{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Setup Colab\n### load files quickly",
      "metadata": {
        "tags": [],
        "cell_id": "00000-aa1ebb43-bd43-4a30-89eb-9a2fbe273df7",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00001-661d49a9-fbb7-418a-93da-aecefc4bf03e",
        "deepnote_cell_type": "code"
      },
      "source": "!git clone https://github.com/sjoerdvandenbos/deeplearning_reproducibility",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00002-f5b082d2-1122-48fd-a78a-3c186e4c5159",
        "deepnote_cell_type": "code"
      },
      "source": "# Select the appropriate folder\nProject_folder = 'deeplearning_reproducibility'\n\n# Allow importing of Python & dataset files\nimport sys\nsys.path.append(Project_folder)",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00001-3f234d6f-7dc7-46fb-beeb-177ee70228b4",
        "deepnote_cell_type": "code"
      },
      "source": "# Install packages on Colab\n!pip install torchinfo gdown\n# Download datasets quickly from Google Drive into fast memory\n!gdown --id 1uLCnPgFH_UP2JNsFUPyiaUkSLWDuNkCd\n# Download CRACK500 model\n!gdown --id 1QMIYYDEt7vdLuD2_X2Chg3VZJGOgRHIJ\n# Download CFD model\n!gdown --id 1nYYNLPxVgeWXNMnY0we5d5hf7wF4zsSt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00002-7d80559c-acec-42c0-af24-d2f0918d7ef3",
        "deepnote_cell_type": "code"
      },
      "source": "# Unzip the datasets\n!unzip datasets.zip",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Reproduce DL\n## Automated Pavement Crack Segmentation\n\nWe start by setting up the actual Architecture. This means making sure all weights are properly initialized and all layers are connected. \n\nWe make use of PyTorch for the implementation.\n\nMultiple parts come together (A U-based ResNet);\n- We recreate ResNet34 and remove the last two layers\n- We made sure that a ResNet-block is either 4 or 6 layers depending on if stride is not 1 (which in our case always happens when the in_channels are not equal to out_channels)\n- We use transfer learning such that the ResNet34 parameters are initialized as if trained on ImageNet\n- We create Squeeze and Excitation blocks that are applied per Channel (cSE) and per Spatial (sSE) (image)\n- These two blocks are combined (scSE) and then the maximum of this is taken\n- Each convolutional layer its parameters are initialized via \"He Kaiming\" method.",
      "metadata": {
        "cell_id": "00000-82d331e0-79e4-40f0-ba43-0ad2ccc7fea5",
        "tags": [],
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00001-7e91ba22-24c3-47de-a4fc-1812208e0fff",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "e71acbdd",
        "execution_millis": 87,
        "output_cleared": false,
        "execution_start": 1618401308314,
        "deepnote_cell_type": "code"
      },
      "source": "# Do all the imports\n## Packages\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\nimport tqdm\nfrom tqdm.notebook import tqdm\nfrom torchinfo import summary\nimport torch\nimport pandas as pd\n\n\n## Project\nfrom architecture import main\nfrom loss.loss import batch_dice_loss\nfrom utils.layers import layer_split\nfrom utils.retrieve_device import try_gpu\nfrom utils.dataset import get_data_loaders\nfrom evaluation.binary_classification import get_prec_recall, get_f1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00004-a65cc30d-dddc-41df-9d94-28845042d191",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 1958,
        "output_cleared": true,
        "source_hash": null,
        "tags": [],
        "execution_start": 1617360992742,
        "is_code_hidden": false,
        "deepnote_cell_type": "code"
      },
      "source": "# Always needs to be a factor of 3\n# Phase 1 = 1/3 time, Phase 2 = 2/3 time\nEPOCHS = 90\nepochs_1 = ( EPOCHS // 3 )\nepochs_2 = ( EPOCHS // 3 ) * 2\n\n# Define list to store losses and performances of each interation\nmetrics = []\n# Try using gpu\ndevice = try_gpu()\n#Initialize network\nnetwork = main.Net()\n#Initiliaze loss function\ncriterion = batch_dice_loss\n\n# Split layers into three, for seperate optimization\nlayer_1, layer_2, layer_3 = layer_split(network)\ndatasetname = \"CFD\"\n\noptimizer = torch.optim.AdamW([\n    {'params': layer_1, 'name': 'layer_1'},\n    {'params': layer_2, 'name': 'layer_2'},\n    {'params': layer_3, 'name': 'layer_3'}], betas=(0.9, 0.999), weight_decay = 0.01)\n\n# Random data loader split seed\nsplit_seed = 42\n## batch sizes (dependend on hardware)\n# Train: should be neither too small nor too large (CFD: 5, C5D: 30) - Colab Pro\nbs_train = 5\n# Test: should be as high as possible (CFD: 48, C5D: 150) - Colab Pro\nbs_test = 48\n\n# Image factor explanation:\n# 1 = 320, 0.8 = 256, 0.4 = 128\n# Get dataloaders (128x128)\ndataset, train_loader, test_loader = get_data_loaders(\n    split_seed, \n    bs_train, \n    bs_test, \n    0.4, \n    datasetname\n    )\n\n# Look at this more carefully\n# it should do this:\n# - max lr is 1.0\n# - start at 5% (0.05) of max_lr \n# - linearly build up\n# - max_lr at (total_epoch * 0.4)\n# - linearly break down\n# - end at 0.00005 lr at last epoch\n# Three phase: \n# - Up from initial to max,\n# - Down from max to initial,\n# - Down from initial to minimum\nscheduler = torch.optim.lr_scheduler.OneCycleLR(\n    optimizer,\n    max_lr=1.0,\n    epochs=EPOCHS,\n    steps_per_epoch=len(train_loader),\n    anneal_strategy='linear',\n    pct_start=0.4, \n    div_factor=20,\n    final_div_factor=20000,\n    three_phase=True\n    )\n\nfor epoch in tqdm(range(EPOCHS)):\n    # Network in training mode and to device\n    network.train()\n    network.to(device)\n    \n    optimizer.param_groups[0][\"lr\"] = 0 if epoch < epochs_1 else optimizer.param_groups[2][\"lr\"] / 9\n    optimizer.param_groups[1][\"lr\"] = optimizer.param_groups[2][\"lr\"] / 3\n\n    print(f\"epoch: {epoch+1}, lr_layer_3 = {optimizer.param_groups[2]['lr']}\")\n    \n    if (epoch == epochs_1):\n        # Get dataloaders (256x256)\n        dataset, train_loader, test_loader = get_data_loaders(\n            split_seed, \n            bs_train, \n            bs_test, \n            0.8, \n            datasetname\n            )\n\n    if (epoch == epochs_2):\n        # Get dataloaders (320x320)\n        dataset, train_loader, test_loader = get_data_loaders(\n            split_seed, \n            bs_train, \n            bs_test, \n            1, \n            datasetname\n            )\n\n    # Training loop\n    for i, (x_batch, y_batch) in enumerate(train_loader):\n\n        # Set to same device\n        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n\n        # Set the gradients to zero\n        optimizer.zero_grad()\n\n        # Perform forward pass\n        y_pred = network(x_batch)\n\n        # Compute the loss\n        loss = criterion(y_pred, y_batch)\n\n        # Backward computation and update\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n    \n    # Compute precision, recall, and f1 for train and test data\n    if epoch >= EPOCHS - 3:\n        train_prec, train_recall = get_prec_recall(train_loader, network.to(device), device)\n        train_f1 = get_f1(train_prec, train_recall)\n        test_prec, test_recall = get_prec_recall(test_loader, network.to(device), device)\n        test_f1 = get_f1(test_prec, test_recall)\n        metrics.append([train_prec, train_recall, train_f1, test_prec, test_recall, test_f1, loss.tolist()])\n\n        # Print performance\n        print('Epoch: {:.0f}'.format(epoch+1))\n        print(f'Precision, Recall, and F1 of train set: {train_prec}, {train_recall}, {train_f1}')\n        print(f'Precision, Recall, and F1 of test set: {test_prec}, {test_recall}, {test_f1}')\n        print('')\n\n\n# Save model\nmodel_state = network.state_dict()\ntorch.save(model_state, \"model_parameters_CFD.pt\")\n\n# Write metrics to disk\ndf = pd.DataFrame(metrics, columns=[\n    \"train_prec\", \"train_recall\", \"train_f1\", \"test_prec\", \"test_recall\", \"test_f1\", \"loss\"])\ndf.to_csv(\"metrics.csv\", index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00008-55ee9151-d60f-4808-b4e0-9f491fe83c6a",
        "deepnote_cell_type": "code"
      },
      "source": "def epoch_to_PIL(data_loader, network, device) -> dict:\n    converted = {\"xs\": [], \"ys\": [], \"preds\": []}\n    count = 0\n    for x_batch, y_batch in data_loader:\n      if (count > 10):\n        break\n      preds = network(x_batch)\n      converted[\"xs\"].extend(batch_to_PIL(x_batch))\n      converted[\"ys\"].extend(batch_to_PIL(y_batch))\n      converted[\"preds\"].extend(batch_to_PIL(preds))\n      count = count + 1\n    return converted\n\n\ndef batch_to_PIL(tensor_batch) -> list:\n    converted = []\n    for t in tensor_batch:\n        img = transforms.ToPILImage()(t)\n        converted.append(img)\n    return converted\n\n\n# Params\nsplit_seed = 42 # dataset train/test split seed\nbs_train = 5 # batch size train\nbs_test = 20 # batch size test\ndevice = try_gpu() # set to GPU\ndatasetname = \"CFD\" # dataset CRACK500\ndataset, train_loader, test_loader = get_data_loaders(\n            split_seed, \n            bs_train, \n            bs_test, \n            1, \n            datasetname\n            )\nnetwork = main.Net()\nnetwork.load_state_dict(torch.load(\"model_parameters_CFD.pt\"))\nnetwork.eval()\npics = epoch_to_PIL(test_loader, network, device)\nn_examples = 10\nf, axarr = plt.subplots(n_examples, 3, figsize=(15, n_examples*4)) \n\nfor i in range(n_examples):\n    axarr[i][0].imshow(pics[\"xs\"][i])\n    axarr[i][1].imshow(pics[\"ys\"][i])\n    axarr[i][2].imshow(pics[\"preds\"][i])",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00009-33ee83a7-ab83-4eb4-811f-2dc28934f96d",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "e971e76b",
        "execution_millis": 2073,
        "execution_start": 1618401416362,
        "deepnote_cell_type": "code"
      },
      "source": "# Summarize the Architecture as output\nnetwork = main.Net()\ndevice = try_gpu()\nmodel = network.to(device)\n\n# print(network)\nmodel_ouput = summary(\n    model, \n    (1, 3, 320, 480),\n    verbose=2,\n    col_width=16,\n    col_names=[\"kernel_size\", \"input_size\", \"output_size\", \"num_params\"])",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "=============================================================================================================\nLayer (type:depth-idx)                        Kernel Shape     Input Shape      Output Shape     Param #\n=============================================================================================================\n├─Sequential: 1-1                             --               [1, 3, 320, 480] [1, 64, 160, 240] --\n|    └─0.weight                               [64, 3, 7, 7]\n|    └─1.weight                               [64]\n|    └─Conv2d: 2-1                            [3, 64, 7, 7]    [1, 3, 320, 480] [1, 64, 160, 240] 9,408\n|    └─BatchNorm2d: 2-2                       [64]             [1, 64, 160, 240] [1, 64, 160, 240] 128\n|    └─ReLU: 2-3                              --               [1, 64, 160, 240] [1, 64, 160, 240] --\n├─Conv2d: 1-2                                 [64, 128, 1, 1]  [1, 64, 160, 240] [1, 128, 160, 240] 8,320\n├─Sequential: 1-3                             --               [1, 64, 160, 240] [1, 64, 80, 120] --\n|    └─1.0.conv1.weight                       [64, 64, 3, 3]\n|    └─1.0.bn1.weight                         [64]\n|    └─1.0.conv2.weight                       [64, 64, 3, 3]\n|    └─1.0.bn2.weight                         [64]\n|    └─1.1.conv1.weight                       [64, 64, 3, 3]\n|    └─1.1.bn1.weight                         [64]\n|    └─1.1.conv2.weight                       [64, 64, 3, 3]\n|    └─1.1.bn2.weight                         [64]\n|    └─1.2.conv1.weight                       [64, 64, 3, 3]\n|    └─1.2.bn1.weight                         [64]\n|    └─1.2.conv2.weight                       [64, 64, 3, 3]\n|    └─1.2.bn2.weight                         [64]\n|    └─MaxPool2d: 2-4                         --               [1, 64, 160, 240] [1, 64, 80, 120] --\n|    └─Sequential: 2-5                        --               [1, 64, 80, 120] [1, 64, 80, 120] --\n|    |    └─0.conv1.weight                    [64, 64, 3, 3]\n|    |    └─0.bn1.weight                      [64]\n|    |    └─0.conv2.weight                    [64, 64, 3, 3]\n|    |    └─0.bn2.weight                      [64]\n|    |    └─1.conv1.weight                    [64, 64, 3, 3]\n|    |    └─1.bn1.weight                      [64]\n|    |    └─1.conv2.weight                    [64, 64, 3, 3]\n|    |    └─1.bn2.weight                      [64]\n|    |    └─2.conv1.weight                    [64, 64, 3, 3]\n|    |    └─2.bn1.weight                      [64]\n|    |    └─2.conv2.weight                    [64, 64, 3, 3]\n|    |    └─2.bn2.weight                      [64]\n|    |    └─ResBlock: 3-1                     --               [1, 64, 80, 120] [1, 64, 80, 120] 73,984\n|    |    |    └─conv1.weight                 [64, 64, 3, 3]\n|    |    |    └─bn1.weight                   [64]\n|    |    |    └─conv2.weight                 [64, 64, 3, 3]\n|    |    |    └─bn2.weight                   [64]\n|    |    └─ResBlock: 3-2                     --               [1, 64, 80, 120] [1, 64, 80, 120] 73,984\n|    |    |    └─conv1.weight                 [64, 64, 3, 3]\n|    |    |    └─bn1.weight                   [64]\n|    |    |    └─conv2.weight                 [64, 64, 3, 3]\n|    |    |    └─bn2.weight                   [64]\n|    |    └─ResBlock: 3-3                     --               [1, 64, 80, 120] [1, 64, 80, 120] 73,984\n|    |    |    └─conv1.weight                 [64, 64, 3, 3]\n|    |    |    └─bn1.weight                   [64]\n|    |    |    └─conv2.weight                 [64, 64, 3, 3]\n|    |    |    └─bn2.weight                   [64]\n├─Conv2d: 1-4                                 [64, 128, 1, 1]  [1, 64, 80, 120] [1, 128, 80, 120] 8,320\n├─Sequential: 1-5                             --               [1, 64, 80, 120] [1, 128, 40, 60] --\n|    └─0.0.conv1.weight                       [128, 64, 3, 3]\n|    └─0.0.bn1.weight                         [128]\n|    └─0.0.conv2.weight                       [128, 128, 3, 3]\n|    └─0.0.bn2.weight                         [128]\n|    └─0.0.downsample.0.weight                [128, 64, 1, 1]\n|    └─0.0.downsample.1.weight                [128]\n|    └─0.1.conv1.weight                       [128, 128, 3, 3]\n|    └─0.1.bn1.weight                         [128]\n|    └─0.1.conv2.weight                       [128, 128, 3, 3]\n|    └─0.1.bn2.weight                         [128]\n|    └─0.2.conv1.weight                       [128, 128, 3, 3]\n|    └─0.2.bn1.weight                         [128]\n|    └─0.2.conv2.weight                       [128, 128, 3, 3]\n|    └─0.2.bn2.weight                         [128]\n|    └─0.3.conv1.weight                       [128, 128, 3, 3]\n|    └─0.3.bn1.weight                         [128]\n|    └─0.3.conv2.weight                       [128, 128, 3, 3]\n|    └─0.3.bn2.weight                         [128]\n|    └─Sequential: 2-6                        --               [1, 64, 80, 120] [1, 128, 40, 60] --\n|    |    └─0.conv1.weight                    [128, 64, 3, 3]\n|    |    └─0.bn1.weight                      [128]\n|    |    └─0.conv2.weight                    [128, 128, 3, 3]\n|    |    └─0.bn2.weight                      [128]\n|    |    └─0.downsample.0.weight             [128, 64, 1, 1]\n|    |    └─0.downsample.1.weight             [128]\n|    |    └─1.conv1.weight                    [128, 128, 3, 3]\n|    |    └─1.bn1.weight                      [128]\n|    |    └─1.conv2.weight                    [128, 128, 3, 3]\n|    |    └─1.bn2.weight                      [128]\n|    |    └─2.conv1.weight                    [128, 128, 3, 3]\n|    |    └─2.bn1.weight                      [128]\n|    |    └─2.conv2.weight                    [128, 128, 3, 3]\n|    |    └─2.bn2.weight                      [128]\n|    |    └─3.conv1.weight                    [128, 128, 3, 3]\n|    |    └─3.bn1.weight                      [128]\n|    |    └─3.conv2.weight                    [128, 128, 3, 3]\n|    |    └─3.bn2.weight                      [128]\n|    |    └─ResBlock: 3-4                     --               [1, 64, 80, 120] [1, 128, 40, 60] 230,144\n|    |    |    └─conv1.weight                 [128, 64, 3, 3]\n|    |    |    └─bn1.weight                   [128]\n|    |    |    └─conv2.weight                 [128, 128, 3, 3]\n|    |    |    └─bn2.weight                   [128]\n|    |    |    └─downsample.0.weight          [128, 64, 1, 1]\n|    |    |    └─downsample.1.weight          [128]\n|    |    └─ResBlock: 3-5                     --               [1, 128, 40, 60] [1, 128, 40, 60] 295,424\n|    |    |    └─conv1.weight                 [128, 128, 3, 3]\n|    |    |    └─bn1.weight                   [128]\n|    |    |    └─conv2.weight                 [128, 128, 3, 3]\n|    |    |    └─bn2.weight                   [128]\n|    |    └─ResBlock: 3-6                     --               [1, 128, 40, 60] [1, 128, 40, 60] 295,424\n|    |    |    └─conv1.weight                 [128, 128, 3, 3]\n|    |    |    └─bn1.weight                   [128]\n|    |    |    └─conv2.weight                 [128, 128, 3, 3]\n|    |    |    └─bn2.weight                   [128]\n|    |    └─ResBlock: 3-7                     --               [1, 128, 40, 60] [1, 128, 40, 60] 295,424\n|    |    |    └─conv1.weight                 [128, 128, 3, 3]\n|    |    |    └─bn1.weight                   [128]\n|    |    |    └─conv2.weight                 [128, 128, 3, 3]\n|    |    |    └─bn2.weight                   [128]\n├─Conv2d: 1-6                                 [128, 128, 1, 1] [1, 128, 40, 60] [1, 128, 40, 60] 16,512\n├─Sequential: 1-7                             --               [1, 128, 40, 60] [1, 256, 20, 30] --\n|    └─0.0.conv1.weight                       [256, 128, 3, 3]\n|    └─0.0.bn1.weight                         [256]\n|    └─0.0.conv2.weight                       [256, 256, 3, 3]\n|    └─0.0.bn2.weight                         [256]\n|    └─0.0.downsample.0.weight                [256, 128, 1, 1]\n|    └─0.0.downsample.1.weight                [256]\n|    └─0.1.conv1.weight                       [256, 256, 3, 3]\n|    └─0.1.bn1.weight                         [256]\n|    └─0.1.conv2.weight                       [256, 256, 3, 3]\n|    └─0.1.bn2.weight                         [256]\n|    └─0.2.conv1.weight                       [256, 256, 3, 3]\n|    └─0.2.bn1.weight                         [256]\n|    └─0.2.conv2.weight                       [256, 256, 3, 3]\n|    └─0.2.bn2.weight                         [256]\n|    └─0.3.conv1.weight                       [256, 256, 3, 3]\n|    └─0.3.bn1.weight                         [256]\n|    └─0.3.conv2.weight                       [256, 256, 3, 3]\n|    └─0.3.bn2.weight                         [256]\n|    └─0.4.conv1.weight                       [256, 256, 3, 3]\n|    └─0.4.bn1.weight                         [256]\n|    └─0.4.conv2.weight                       [256, 256, 3, 3]\n|    └─0.4.bn2.weight                         [256]\n|    └─0.5.conv1.weight                       [256, 256, 3, 3]\n|    └─0.5.bn1.weight                         [256]\n|    └─0.5.conv2.weight                       [256, 256, 3, 3]\n|    └─0.5.bn2.weight                         [256]\n|    └─Sequential: 2-7                        --               [1, 128, 40, 60] [1, 256, 20, 30] --\n|    |    └─0.conv1.weight                    [256, 128, 3, 3]\n|    |    └─0.bn1.weight                      [256]\n|    |    └─0.conv2.weight                    [256, 256, 3, 3]\n|    |    └─0.bn2.weight                      [256]\n|    |    └─0.downsample.0.weight             [256, 128, 1, 1]\n|    |    └─0.downsample.1.weight             [256]\n|    |    └─1.conv1.weight                    [256, 256, 3, 3]\n|    |    └─1.bn1.weight                      [256]\n|    |    └─1.conv2.weight                    [256, 256, 3, 3]\n|    |    └─1.bn2.weight                      [256]\n|    |    └─2.conv1.weight                    [256, 256, 3, 3]\n|    |    └─2.bn1.weight                      [256]\n|    |    └─2.conv2.weight                    [256, 256, 3, 3]\n|    |    └─2.bn2.weight                      [256]\n|    |    └─3.conv1.weight                    [256, 256, 3, 3]\n|    |    └─3.bn1.weight                      [256]\n|    |    └─3.conv2.weight                    [256, 256, 3, 3]\n|    |    └─3.bn2.weight                      [256]\n|    |    └─4.conv1.weight                    [256, 256, 3, 3]\n|    |    └─4.bn1.weight                      [256]\n|    |    └─4.conv2.weight                    [256, 256, 3, 3]\n|    |    └─4.bn2.weight                      [256]\n|    |    └─5.conv1.weight                    [256, 256, 3, 3]\n|    |    └─5.bn1.weight                      [256]\n|    |    └─5.conv2.weight                    [256, 256, 3, 3]\n|    |    └─5.bn2.weight                      [256]\n|    |    └─ResBlock: 3-8                     --               [1, 128, 40, 60] [1, 256, 20, 30] 919,040\n|    |    |    └─conv1.weight                 [256, 128, 3, 3]\n|    |    |    └─bn1.weight                   [256]\n|    |    |    └─conv2.weight                 [256, 256, 3, 3]\n|    |    |    └─bn2.weight                   [256]\n|    |    |    └─downsample.0.weight          [256, 128, 1, 1]\n|    |    |    └─downsample.1.weight          [256]\n|    |    └─ResBlock: 3-9                     --               [1, 256, 20, 30] [1, 256, 20, 30] 1,180,672\n|    |    |    └─conv1.weight                 [256, 256, 3, 3]\n|    |    |    └─bn1.weight                   [256]\n|    |    |    └─conv2.weight                 [256, 256, 3, 3]\n|    |    |    └─bn2.weight                   [256]\n|    |    └─ResBlock: 3-10                    --               [1, 256, 20, 30] [1, 256, 20, 30] 1,180,672\n|    |    |    └─conv1.weight                 [256, 256, 3, 3]\n|    |    |    └─bn1.weight                   [256]\n|    |    |    └─conv2.weight                 [256, 256, 3, 3]\n|    |    |    └─bn2.weight                   [256]\n|    |    └─ResBlock: 3-11                    --               [1, 256, 20, 30] [1, 256, 20, 30] 1,180,672\n|    |    |    └─conv1.weight                 [256, 256, 3, 3]\n|    |    |    └─bn1.weight                   [256]\n|    |    |    └─conv2.weight                 [256, 256, 3, 3]\n|    |    |    └─bn2.weight                   [256]\n|    |    └─ResBlock: 3-12                    --               [1, 256, 20, 30] [1, 256, 20, 30] 1,180,672\n|    |    |    └─conv1.weight                 [256, 256, 3, 3]\n|    |    |    └─bn1.weight                   [256]\n|    |    |    └─conv2.weight                 [256, 256, 3, 3]\n|    |    |    └─bn2.weight                   [256]\n|    |    └─ResBlock: 3-13                    --               [1, 256, 20, 30] [1, 256, 20, 30] 1,180,672\n|    |    |    └─conv1.weight                 [256, 256, 3, 3]\n|    |    |    └─bn1.weight                   [256]\n|    |    |    └─conv2.weight                 [256, 256, 3, 3]\n|    |    |    └─bn2.weight                   [256]\n├─Conv2d: 1-8                                 [256, 128, 1, 1] [1, 256, 20, 30] [1, 128, 20, 30] 32,896\n├─Sequential: 1-9                             --               [1, 256, 20, 30] [1, 512, 10, 15] --\n|    └─0.0.conv1.weight                       [512, 256, 3, 3]\n|    └─0.0.bn1.weight                         [512]\n|    └─0.0.conv2.weight                       [512, 512, 3, 3]\n|    └─0.0.bn2.weight                         [512]\n|    └─0.0.downsample.0.weight                [512, 256, 1, 1]\n|    └─0.0.downsample.1.weight                [512]\n|    └─0.1.conv1.weight                       [512, 512, 3, 3]\n|    └─0.1.bn1.weight                         [512]\n|    └─0.1.conv2.weight                       [512, 512, 3, 3]\n|    └─0.1.bn2.weight                         [512]\n|    └─0.2.conv1.weight                       [512, 512, 3, 3]\n|    └─0.2.bn1.weight                         [512]\n|    └─0.2.conv2.weight                       [512, 512, 3, 3]\n|    └─0.2.bn2.weight                         [512]\n|    └─Sequential: 2-8                        --               [1, 256, 20, 30] [1, 512, 10, 15] --\n|    |    └─0.conv1.weight                    [512, 256, 3, 3]\n|    |    └─0.bn1.weight                      [512]\n|    |    └─0.conv2.weight                    [512, 512, 3, 3]\n|    |    └─0.bn2.weight                      [512]\n|    |    └─0.downsample.0.weight             [512, 256, 1, 1]\n|    |    └─0.downsample.1.weight             [512]\n|    |    └─1.conv1.weight                    [512, 512, 3, 3]\n|    |    └─1.bn1.weight                      [512]\n|    |    └─1.conv2.weight                    [512, 512, 3, 3]\n|    |    └─1.bn2.weight                      [512]\n|    |    └─2.conv1.weight                    [512, 512, 3, 3]\n|    |    └─2.bn1.weight                      [512]\n|    |    └─2.conv2.weight                    [512, 512, 3, 3]\n|    |    └─2.bn2.weight                      [512]\n|    |    └─ResBlock: 3-14                    --               [1, 256, 20, 30] [1, 512, 10, 15] 3,673,088\n|    |    |    └─conv1.weight                 [512, 256, 3, 3]\n|    |    |    └─bn1.weight                   [512]\n|    |    |    └─conv2.weight                 [512, 512, 3, 3]\n|    |    |    └─bn2.weight                   [512]\n|    |    |    └─downsample.0.weight          [512, 256, 1, 1]\n|    |    |    └─downsample.1.weight          [512]\n|    |    └─ResBlock: 3-15                    --               [1, 512, 10, 15] [1, 512, 10, 15] 4,720,640\n|    |    |    └─conv1.weight                 [512, 512, 3, 3]\n|    |    |    └─bn1.weight                   [512]\n|    |    |    └─conv2.weight                 [512, 512, 3, 3]\n|    |    |    └─bn2.weight                   [512]\n|    |    └─ResBlock: 3-16                    --               [1, 512, 10, 15] [1, 512, 10, 15] 4,720,640\n|    |    |    └─conv1.weight                 [512, 512, 3, 3]\n|    |    |    └─bn1.weight                   [512]\n|    |    |    └─conv2.weight                 [512, 512, 3, 3]\n|    |    |    └─bn2.weight                   [512]\n├─Conv2d: 1-10                                [512, 512, 1, 1] [1, 512, 10, 15] [1, 512, 10, 15] 262,656\n├─ConvTranspose2d: 1-11                       [128, 512, 2, 2] [1, 512, 10, 15] [1, 128, 20, 30] 262,272\n├─UpsampBlock: 1-12                           --               [1, 256, 20, 30] [1, 256, 20, 30] --\n|    └─bn.weight                              [256]\n|    └─scse.CSE.fc1.weight                    [128, 256]\n|    └─scse.CSE.fc2.weight                    [256, 128]\n|    └─scse.SSE.conv.weight                   [1, 256, 1, 1]\n|    └─ReLU: 2-9                              --               [1, 256, 20, 30] [1, 256, 20, 30] --\n|    └─BatchNorm2d: 2-10                      [256]            [1, 256, 20, 30] [1, 256, 20, 30] 512\n|    └─SCSEBlock: 2-11                        --               [1, 256, 20, 30] [1, 256, 20, 30] --\n|    |    └─CSE.fc1.weight                    [128, 256]\n|    |    └─CSE.fc2.weight                    [256, 128]\n|    |    └─SSE.conv.weight                   [1, 256, 1, 1]\n|    |    └─CSEBlock: 3-17                    --               [1, 256, 20, 30] [1, 256, 20, 30] 65,920\n|    |    |    └─fc1.weight                   [128, 256]\n|    |    |    └─fc2.weight                   [256, 128]\n|    |    └─SSEBlock: 3-18                    --               [1, 256, 20, 30] [1, 256, 20, 30] 257\n|    |    |    └─conv.weight                  [1, 256, 1, 1]\n├─ConvTranspose2d: 1-13                       [128, 256, 2, 2] [1, 256, 20, 30] [1, 128, 40, 60] 131,200\n├─UpsampBlock: 1-14                           --               [1, 256, 40, 60] [1, 256, 40, 60] --\n|    └─bn.weight                              [256]\n|    └─scse.CSE.fc1.weight                    [128, 256]\n|    └─scse.CSE.fc2.weight                    [256, 128]\n|    └─scse.SSE.conv.weight                   [1, 256, 1, 1]\n|    └─ReLU: 2-12                             --               [1, 256, 40, 60] [1, 256, 40, 60] --\n|    └─BatchNorm2d: 2-13                      [256]            [1, 256, 40, 60] [1, 256, 40, 60] 512\n|    └─SCSEBlock: 2-14                        --               [1, 256, 40, 60] [1, 256, 40, 60] --\n|    |    └─CSE.fc1.weight                    [128, 256]\n|    |    └─CSE.fc2.weight                    [256, 128]\n|    |    └─SSE.conv.weight                   [1, 256, 1, 1]\n|    |    └─CSEBlock: 3-19                    --               [1, 256, 40, 60] [1, 256, 40, 60] 65,920\n|    |    |    └─fc1.weight                   [128, 256]\n|    |    |    └─fc2.weight                   [256, 128]\n|    |    └─SSEBlock: 3-20                    --               [1, 256, 40, 60] [1, 256, 40, 60] 257\n|    |    |    └─conv.weight                  [1, 256, 1, 1]\n├─ConvTranspose2d: 1-15                       [128, 256, 2, 2] [1, 256, 40, 60] [1, 128, 80, 120] 131,200\n├─UpsampBlock: 1-16                           --               [1, 256, 80, 120] [1, 256, 80, 120] --\n|    └─bn.weight                              [256]\n|    └─scse.CSE.fc1.weight                    [128, 256]\n|    └─scse.CSE.fc2.weight                    [256, 128]\n|    └─scse.SSE.conv.weight                   [1, 256, 1, 1]\n|    └─ReLU: 2-15                             --               [1, 256, 80, 120] [1, 256, 80, 120] --\n|    └─BatchNorm2d: 2-16                      [256]            [1, 256, 80, 120] [1, 256, 80, 120] 512\n|    └─SCSEBlock: 2-17                        --               [1, 256, 80, 120] [1, 256, 80, 120] --\n|    |    └─CSE.fc1.weight                    [128, 256]\n|    |    └─CSE.fc2.weight                    [256, 128]\n|    |    └─SSE.conv.weight                   [1, 256, 1, 1]\n|    |    └─CSEBlock: 3-21                    --               [1, 256, 80, 120] [1, 256, 80, 120] 65,920\n|    |    |    └─fc1.weight                   [128, 256]\n|    |    |    └─fc2.weight                   [256, 128]\n|    |    └─SSEBlock: 3-22                    --               [1, 256, 80, 120] [1, 256, 80, 120] 257\n|    |    |    └─conv.weight                  [1, 256, 1, 1]\n├─ConvTranspose2d: 1-17                       [128, 256, 2, 2] [1, 256, 80, 120] [1, 128, 160, 240] 131,200\n├─UpsampBlock: 1-18                           --               [1, 256, 160, 240] [1, 256, 160, 240] --\n|    └─bn.weight                              [256]\n|    └─scse.CSE.fc1.weight                    [128, 256]\n|    └─scse.CSE.fc2.weight                    [256, 128]\n|    └─scse.SSE.conv.weight                   [1, 256, 1, 1]\n|    └─ReLU: 2-18                             --               [1, 256, 160, 240] [1, 256, 160, 240] --\n|    └─BatchNorm2d: 2-19                      [256]            [1, 256, 160, 240] [1, 256, 160, 240] 512\n|    └─SCSEBlock: 2-20                        --               [1, 256, 160, 240] [1, 256, 160, 240] --\n|    |    └─CSE.fc1.weight                    [128, 256]\n|    |    └─CSE.fc2.weight                    [256, 128]\n|    |    └─SSE.conv.weight                   [1, 256, 1, 1]\n|    |    └─CSEBlock: 3-23                    --               [1, 256, 160, 240] [1, 256, 160, 240] 65,920\n|    |    |    └─fc1.weight                   [128, 256]\n|    |    |    └─fc2.weight                   [256, 128]\n|    |    └─SSEBlock: 3-24                    --               [1, 256, 160, 240] [1, 256, 160, 240] 257\n|    |    |    └─conv.weight                  [1, 256, 1, 1]\n├─ConvTranspose2d: 1-19                       [1, 256, 2, 2]   [1, 256, 160, 240] [1, 1, 320, 480] 1,025\n├─Sigmoid: 1-20                               --               [1, 1, 320, 480] [1, 1, 320, 480] --\n=============================================================================================================\nTotal params: 22,537,029\nTrainable params: 22,537,029\nNon-trainable params: 0\nTotal mult-adds (G): 44.71\n=============================================================================================================\nInput size (MB): 1.84\nForward/backward pass size (MB): 385.65\nParams size (MB): 90.15\nEstimated Total Size (MB): 477.64\n=============================================================================================================\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=42655a99-137b-4077-956a-42bbbfa0710c' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "tags": [],
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 4,
  "metadata": {
    "deepnote": {
      "is_reactive": false
    },
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "96775278-d606-4bc7-a96c-64fcdaf37c69",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  }
}