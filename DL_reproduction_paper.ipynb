{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Reproduce DL\n## Automated Pavement Crack Segmentation\n\nWe start by setting up the actual Architecture. This means making sure all weights are properly initialized and all layers are connected. \n\nWe make use of PyTorch for the implementation.\n\nMultiple parts come together (A U-based ResNet);\n- We recreate ResNet34 and remove the last two layers\n- We made sure that a ResNet-block is either 4 or 6 layers depending on if stride is not 1 (which in our case always happens when the in_channels are not equal to out_channels)\n- We use transfer learning such that the ResNet34 parameters are initialized as if trained on ImageNet\n- We create Squeeze and Excitation blocks that are applied per Channel (cSE) and per Spatial (sSE) (image)\n- These two blocks are combined (scSE) and then the maximum of this is taken\n- Each convolutional layer its parameters are initialized via \"He Kaiming\" method.",
      "metadata": {
        "cell_id": "00000-82d331e0-79e4-40f0-ba43-0ad2ccc7fea5",
        "tags": [],
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00001-7e91ba22-24c3-47de-a4fc-1812208e0fff",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "7bddc963",
        "execution_millis": 4261,
        "output_cleared": true,
        "execution_start": 1618392447957,
        "deepnote_cell_type": "code"
      },
      "source": "# Do all the imports\n## Packages\nfrom torch.utils.data import random_split\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom torchvision.transforms.functional import InterpolationMode\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom tqdm.notebook import tqdm as tqdm\nfrom torchsummary import summary\nimport torch.nn as nn\nimport torch\nimport pandas as pd\nimport os\n\n## Project\nfrom architecture import main\nfrom datasets.CFD.CFDdata import CFD\nfrom datasets.CRACK500.CRACKdata import C5D\nfrom loss.loss import batch_dice_loss\nfrom utils.layers import layer_split\nfrom utils.retrieve_device import try_gpu",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00002-5d73a80a-2305-4196-baa2-0401984a01b8",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "b5c1a620",
        "execution_millis": 1,
        "execution_start": 1618344907704,
        "deepnote_cell_type": "code"
      },
      "source": "# Image factor explanation:\n# 1 = 320\n# 0.8 = 256\n# 0.4 = 128\nsplit_seed = 42\n\ndef get_data_loaders(img_factor=1, dataset=\"CFD\"):\n    # Define standard variables\n    current_path = os.path.abspath(os.getcwd())\n    image = \"/datasets/CFD/cfd_image/\"\n    gt = \"/datasets/CFD/seg_gt/\"\n    ratio = [71, 47]\n    batch_size = 10\n    batch_size_t = 47\n\n    if dataset == \"CRACK500\":\n        image = \"/datasets/CRACK500/crack_image/\"\n        gt = \"/datasets/CRACK500/seg_gt/\"\n        ratio = [2021, 1347]\n\n    tf_compos, tf_compos_gt = get_transforms(img_factor)\n    if dataset == \"CFD\":\n        dataset = CFD(current_path + image, tf_compos, current_path + gt, tf_compos_gt)\n    else:\n        dataset = C5D(current_path + image, tf_compos, current_path + gt, tf_compos_gt)\n\n    # Manual seed added such that same split is kept,\n    # even though a new split is made with different sizes\n    print(f\"dataset len: {len(dataset)}\")\n    train_data, test_data = random_split(dataset, ratio,\n                                         generator=torch.Generator().manual_seed(split_seed))\n    train_loader = DataLoader(train_data, batch_size=batch_size)\n    test_loader = DataLoader(test_data, batch_size=batch_size_t)\n    \n    print(f\"dataset: {len(dataset)}, objects_train: {len(train_data)}, BS_train: {batch_size}, dataloader len: {len(train_loader)}\")\n    print(f\"objects_test: {len(test_data)}, BS_test: {batch_size_t}, dataloader len: {len(test_loader)}\")\n\n    return dataset, train_loader, test_loader\n\n\ndef get_transforms(img_factor):\n    resize_image = tuple(int(img_factor * x) for x in (320, 480))\n    crop_image = resize_image[0]\n\n    shared_transforms = [\n        transforms.RandomCrop(crop_image),\n        transforms.Pad(200, padding_mode='reflect'),\n        transforms.RandomRotation((0,360)),\n        transforms.CenterCrop(crop_image),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n    ]\n    # Bilinear interpolation since value can be [-255, +255]\n    tf_compos = transforms.Compose([\n        transforms.Resize(resize_image, interpolation=InterpolationMode.BILINEAR),\n        *shared_transforms, \n        transforms.ColorJitter(brightness=0.05, contrast=0.05), \n        transforms.ToTensor()\n        ])\n    # NN interpolation since value can only be [0 or 1], \n    # Bilinear, should be tested at some point, however.\n    tf_compos_gt = transforms.Compose([\n        transforms.Resize(resize_image, interpolation=InterpolationMode.NEAREST),\n        *shared_transforms, \n        transforms.ToTensor()\n        ])\n    return tf_compos, tf_compos_gt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00002-150d101a-f65c-4901-81b9-f36c7959da0f",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "daac1ea6",
        "execution_millis": 21,
        "execution_start": 1618344914060,
        "deepnote_cell_type": "code"
      },
      "source": "def batch_get_new_label(old_labels, predictions):\n    old_with_padding = nn.ReplicationPad2d(2)(old_labels)\n    extended_labels = nn.MaxPool2d(5, stride=1)(old_with_padding)\n    extension = extended_labels - old_labels\n    \n    # Transforms only the extension area to contain 0 if prediction is 0 and 1 if prediction is 1\n    ext_isect_pred = torch.logical_and(extension, predictions)\n    \n    # Combines this new extension area with old label\n    new_label = torch.logical_or(old_labels, ext_isect_pred).float()\n    return new_label\n\n\ndef get_prec_recall(data_loader, network, device=torch.device(\"cpu\")):\n    network.eval()\n    isect_sum = torch.tensor([0], dtype=torch.float32, device=device)\n    positive_predicts_pixels = 0\n    positive_truth_pixels = 0\n\n    for X, y in data_loader:\n        # Copy the data to device.\n        X, y = X.to(device), y.to(device)\n        with torch.no_grad():\n            pred = (network(X) >= 0.5).float()\n            y_ext = batch_get_new_label(y, pred)\n            isect_sum += torch.sum(torch.logical_and(y_ext, pred))\n            positive_predicts_pixels += torch.sum(pred)\n            positive_truth_pixels += torch.sum(y_ext)\n\n    precision = ( isect_sum + 1e-8 ) / ( positive_predicts_pixels + 1e-8 )\n    recall = ( isect_sum + 1e-8 )/ ( positive_truth_pixels + 1e-8 )\n    return (precision.item(), recall.item())\n\n\ndef get_f1(precision, recall):\n    return 2*precision*recall / (precision+recall)",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00004-a65cc30d-dddc-41df-9d94-28845042d191",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 1958,
        "output_cleared": true,
        "source_hash": null,
        "tags": [],
        "execution_start": 1617360992742,
        "deepnote_cell_type": "code"
      },
      "source": "# Always needs to be a factor of 3\n# Phase 1 = 1/3 time, Phase 2 = 2/3 time\nEPOCHS = 90\nepochs_1 = ( EPOCHS // 3 )\nepochs_2 = ( EPOCHS // 3 ) * 2\n\n# Define list to store losses and performances of each interation\nmetrics = []\n\n# Try using gpu\ndevice = torch.device('cuda:0')\n\n#Initialize network\nnetwork = main.Net()\n\n#Initiliaze loss function\ncriterion = batch_dice_loss\n\n# Split layers into three, for seperate optimization\nlayer_1, layer_2, layer_3 = layer_split(network)\ndatasetname = \"CFD\"\n\noptimizer = torch.optim.AdamW([\n    {'params': layer_1, 'name': 'layer_1'},\n    {'params': layer_2, 'name': 'layer_2'},\n    {'params': layer_3, 'name': 'layer_3'}], betas=(0.9, 0.999), weight_decay = 0.01)\n\n# Get dataloaders (128x128)\ndataset, train_loader, test_loader = get_data_loaders(0.4, datasetname)\n\n# Look at this more carefully\n# it should do this:\n# - max lr is 1.0\n# - start at 5% (0.05) of max_lr \n# - linearly build up\n# - max_lr at (total_epoch * 0.4)\n# - linearly break down\n# - end at 0.00005 lr at last epoch\n# Three phase: \n# - Up from initial to max,\n# - Down from max to initial,\n# - Down from initial to minimum\nscheduler = torch.optim.lr_scheduler.OneCycleLR(\n    optimizer,\n    max_lr=1.0,\n    epochs=EPOCHS,\n    steps_per_epoch=len(train_loader),\n    anneal_strategy='linear',\n    pct_start=0.4, \n    div_factor=20,\n    final_div_factor=20000,\n    three_phase=True\n    )\n\nfor epoch in tqdm(range(EPOCHS)):\n    # Network in training mode and to device\n    network.train()\n    network.to(device)\n    \n    optimizer.param_groups[0][\"lr\"] = 0 if epoch < epochs_1 else optimizer.param_groups[2][\"lr\"] / 9\n    optimizer.param_groups[1][\"lr\"] = optimizer.param_groups[2][\"lr\"] / 3\n\n    print(f\"epoch: {epoch+1}, lr_layer_3 = {optimizer.param_groups[2]['lr']}\")\n    \n    if (epoch == epochs_1):\n        # Get dataloaders (256x256)\n        dataset, train_loader, test_loader = get_data_loaders(0.8, datasetname)\n\n    if (epoch == epochs_2):\n        # Get dataloaders (320x320)\n        dataset, train_loader, test_loader = get_data_loaders(1, datasetname)\n\n    # Training loop\n    for i, (x_batch, y_batch) in enumerate(train_loader):\n\n        # Set to same device\n        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n\n        # Set the gradients to zero\n        optimizer.zero_grad()\n\n        # Perform forward pass\n        y_pred = network(x_batch)\n\n        # Compute the loss\n        loss = criterion(y_pred, y_batch)\n\n        # Backward computation and update\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n    \n    # Compute precision, recall, and f1 for train and test data\n    if epoch >= EPOCHS - 3:\n        train_prec, train_recall = get_prec_recall(train_loader, network.to(\"cpu\"))\n        train_f1 = get_f1(train_prec, train_recall)\n        test_prec, test_recall = get_prec_recall(test_loader, network.to(\"cpu\"))\n        test_f1 = get_f1(test_prec, test_recall)\n        metrics.append([train_prec, train_recall, train_f1, test_prec, test_recall, test_f1, loss.tolist()])\n\n        # Print performance\n        print('Epoch: {:.0f}'.format(epoch+1))\n        print(f'Precision, Recall, and F1 of train set: {train_prec}, {train_recall}, {train_f1}')\n        print(f'Precision, Recall, and F1 of test set: {test_prec}, {test_recall}, {test_f1}')\n        print('')\n\n\n# Save model\nmodel_state = network.state_dict()\nreproduction_info = { \"params\": model_state, \"split_seed\": split_seed }\ntorch.save(model_state, \"model_parameters.pt\")\n\n# Write metrics to disk\ndf = pd.DataFrame(metrics, columns=[\n    \"train_prec\", \"train_recall\", \"train_f1\", \"test_prec\", \"test_recall\", \"test_f1\", \"loss\"])\ndf.to_csv(\"metrics.csv\", index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00009-33ee83a7-ab83-4eb4-811f-2dc28934f96d",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "89401f6a",
        "execution_millis": 4528,
        "execution_start": 1618344919590,
        "deepnote_cell_type": "code"
      },
      "source": "# Summarize the Architecture as output\nnetwork = main.Net()\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel = network.to(device)\n\n# print(network)\nsummary(model, input_size=(3, 320, 480))",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1         [-1, 64, 160, 240]           9,408\n       BatchNorm2d-2         [-1, 64, 160, 240]             128\n              ReLU-3         [-1, 64, 160, 240]               0\n            Conv2d-4        [-1, 128, 160, 240]           8,320\n         MaxPool2d-5          [-1, 64, 80, 120]               0\n            Conv2d-6          [-1, 64, 80, 120]          36,864\n       BatchNorm2d-7          [-1, 64, 80, 120]             128\n              ReLU-8          [-1, 64, 80, 120]               0\n            Conv2d-9          [-1, 64, 80, 120]          36,864\n      BatchNorm2d-10          [-1, 64, 80, 120]             128\n             ReLU-11          [-1, 64, 80, 120]               0\n         ResBlock-12          [-1, 64, 80, 120]               0\n           Conv2d-13          [-1, 64, 80, 120]          36,864\n      BatchNorm2d-14          [-1, 64, 80, 120]             128\n             ReLU-15          [-1, 64, 80, 120]               0\n           Conv2d-16          [-1, 64, 80, 120]          36,864\n      BatchNorm2d-17          [-1, 64, 80, 120]             128\n             ReLU-18          [-1, 64, 80, 120]               0\n         ResBlock-19          [-1, 64, 80, 120]               0\n           Conv2d-20          [-1, 64, 80, 120]          36,864\n      BatchNorm2d-21          [-1, 64, 80, 120]             128\n             ReLU-22          [-1, 64, 80, 120]               0\n           Conv2d-23          [-1, 64, 80, 120]          36,864\n      BatchNorm2d-24          [-1, 64, 80, 120]             128\n             ReLU-25          [-1, 64, 80, 120]               0\n         ResBlock-26          [-1, 64, 80, 120]               0\n           Conv2d-27         [-1, 128, 80, 120]           8,320\n           Conv2d-28          [-1, 128, 40, 60]          73,728\n      BatchNorm2d-29          [-1, 128, 40, 60]             256\n             ReLU-30          [-1, 128, 40, 60]               0\n           Conv2d-31          [-1, 128, 40, 60]         147,456\n      BatchNorm2d-32          [-1, 128, 40, 60]             256\n           Conv2d-33          [-1, 128, 40, 60]           8,192\n      BatchNorm2d-34          [-1, 128, 40, 60]             256\n             ReLU-35          [-1, 128, 40, 60]               0\n         ResBlock-36          [-1, 128, 40, 60]               0\n           Conv2d-37          [-1, 128, 40, 60]         147,456\n      BatchNorm2d-38          [-1, 128, 40, 60]             256\n             ReLU-39          [-1, 128, 40, 60]               0\n           Conv2d-40          [-1, 128, 40, 60]         147,456\n      BatchNorm2d-41          [-1, 128, 40, 60]             256\n             ReLU-42          [-1, 128, 40, 60]               0\n         ResBlock-43          [-1, 128, 40, 60]               0\n           Conv2d-44          [-1, 128, 40, 60]         147,456\n      BatchNorm2d-45          [-1, 128, 40, 60]             256\n             ReLU-46          [-1, 128, 40, 60]               0\n           Conv2d-47          [-1, 128, 40, 60]         147,456\n      BatchNorm2d-48          [-1, 128, 40, 60]             256\n             ReLU-49          [-1, 128, 40, 60]               0\n         ResBlock-50          [-1, 128, 40, 60]               0\n           Conv2d-51          [-1, 128, 40, 60]         147,456\n      BatchNorm2d-52          [-1, 128, 40, 60]             256\n             ReLU-53          [-1, 128, 40, 60]               0\n           Conv2d-54          [-1, 128, 40, 60]         147,456\n      BatchNorm2d-55          [-1, 128, 40, 60]             256\n             ReLU-56          [-1, 128, 40, 60]               0\n         ResBlock-57          [-1, 128, 40, 60]               0\n           Conv2d-58          [-1, 128, 40, 60]          16,512\n           Conv2d-59          [-1, 256, 20, 30]         294,912\n      BatchNorm2d-60          [-1, 256, 20, 30]             512\n             ReLU-61          [-1, 256, 20, 30]               0\n           Conv2d-62          [-1, 256, 20, 30]         589,824\n      BatchNorm2d-63          [-1, 256, 20, 30]             512\n           Conv2d-64          [-1, 256, 20, 30]          32,768\n      BatchNorm2d-65          [-1, 256, 20, 30]             512\n             ReLU-66          [-1, 256, 20, 30]               0\n         ResBlock-67          [-1, 256, 20, 30]               0\n           Conv2d-68          [-1, 256, 20, 30]         589,824\n      BatchNorm2d-69          [-1, 256, 20, 30]             512\n             ReLU-70          [-1, 256, 20, 30]               0\n           Conv2d-71          [-1, 256, 20, 30]         589,824\n      BatchNorm2d-72          [-1, 256, 20, 30]             512\n             ReLU-73          [-1, 256, 20, 30]               0\n         ResBlock-74          [-1, 256, 20, 30]               0\n           Conv2d-75          [-1, 256, 20, 30]         589,824\n      BatchNorm2d-76          [-1, 256, 20, 30]             512\n             ReLU-77          [-1, 256, 20, 30]               0\n           Conv2d-78          [-1, 256, 20, 30]         589,824\n      BatchNorm2d-79          [-1, 256, 20, 30]             512\n             ReLU-80          [-1, 256, 20, 30]               0\n         ResBlock-81          [-1, 256, 20, 30]               0\n           Conv2d-82          [-1, 256, 20, 30]         589,824\n      BatchNorm2d-83          [-1, 256, 20, 30]             512\n             ReLU-84          [-1, 256, 20, 30]               0\n           Conv2d-85          [-1, 256, 20, 30]         589,824\n      BatchNorm2d-86          [-1, 256, 20, 30]             512\n             ReLU-87          [-1, 256, 20, 30]               0\n         ResBlock-88          [-1, 256, 20, 30]               0\n           Conv2d-89          [-1, 256, 20, 30]         589,824\n      BatchNorm2d-90          [-1, 256, 20, 30]             512\n             ReLU-91          [-1, 256, 20, 30]               0\n           Conv2d-92          [-1, 256, 20, 30]         589,824\n      BatchNorm2d-93          [-1, 256, 20, 30]             512\n             ReLU-94          [-1, 256, 20, 30]               0\n         ResBlock-95          [-1, 256, 20, 30]               0\n           Conv2d-96          [-1, 256, 20, 30]         589,824\n      BatchNorm2d-97          [-1, 256, 20, 30]             512\n             ReLU-98          [-1, 256, 20, 30]               0\n           Conv2d-99          [-1, 256, 20, 30]         589,824\n     BatchNorm2d-100          [-1, 256, 20, 30]             512\n            ReLU-101          [-1, 256, 20, 30]               0\n        ResBlock-102          [-1, 256, 20, 30]               0\n          Conv2d-103          [-1, 128, 20, 30]          32,896\n          Conv2d-104          [-1, 512, 10, 15]       1,179,648\n     BatchNorm2d-105          [-1, 512, 10, 15]           1,024\n            ReLU-106          [-1, 512, 10, 15]               0\n          Conv2d-107          [-1, 512, 10, 15]       2,359,296\n     BatchNorm2d-108          [-1, 512, 10, 15]           1,024\n          Conv2d-109          [-1, 512, 10, 15]         131,072\n     BatchNorm2d-110          [-1, 512, 10, 15]           1,024\n            ReLU-111          [-1, 512, 10, 15]               0\n        ResBlock-112          [-1, 512, 10, 15]               0\n          Conv2d-113          [-1, 512, 10, 15]       2,359,296\n     BatchNorm2d-114          [-1, 512, 10, 15]           1,024\n            ReLU-115          [-1, 512, 10, 15]               0\n          Conv2d-116          [-1, 512, 10, 15]       2,359,296\n     BatchNorm2d-117          [-1, 512, 10, 15]           1,024\n            ReLU-118          [-1, 512, 10, 15]               0\n        ResBlock-119          [-1, 512, 10, 15]               0\n          Conv2d-120          [-1, 512, 10, 15]       2,359,296\n     BatchNorm2d-121          [-1, 512, 10, 15]           1,024\n            ReLU-122          [-1, 512, 10, 15]               0\n          Conv2d-123          [-1, 512, 10, 15]       2,359,296\n     BatchNorm2d-124          [-1, 512, 10, 15]           1,024\n            ReLU-125          [-1, 512, 10, 15]               0\n        ResBlock-126          [-1, 512, 10, 15]               0\n          Conv2d-127          [-1, 512, 10, 15]         262,656\n ConvTranspose2d-128          [-1, 128, 20, 30]         262,272\n            ReLU-129          [-1, 256, 20, 30]               0\n     BatchNorm2d-130          [-1, 256, 20, 30]             512\nAdaptiveAvgPool2d-131            [-1, 256, 1, 1]               0\n          Linear-132                  [-1, 128]          32,896\n            ReLU-133                  [-1, 128]               0\n          Linear-134                  [-1, 256]          33,024\n         Sigmoid-135                  [-1, 256]               0\n        CSEBlock-136          [-1, 256, 20, 30]               0\n          Conv2d-137            [-1, 1, 20, 30]             257\n         Sigmoid-138            [-1, 1, 20, 30]               0\n        SSEBlock-139          [-1, 256, 20, 30]               0\n       SCSEBlock-140          [-1, 256, 20, 30]               0\n     UpsampBlock-141          [-1, 256, 20, 30]               0\n ConvTranspose2d-142          [-1, 128, 40, 60]         131,200\n            ReLU-143          [-1, 256, 40, 60]               0\n     BatchNorm2d-144          [-1, 256, 40, 60]             512\nAdaptiveAvgPool2d-145            [-1, 256, 1, 1]               0\n          Linear-146                  [-1, 128]          32,896\n            ReLU-147                  [-1, 128]               0\n          Linear-148                  [-1, 256]          33,024\n         Sigmoid-149                  [-1, 256]               0\n        CSEBlock-150          [-1, 256, 40, 60]               0\n          Conv2d-151            [-1, 1, 40, 60]             257\n         Sigmoid-152            [-1, 1, 40, 60]               0\n        SSEBlock-153          [-1, 256, 40, 60]               0\n       SCSEBlock-154          [-1, 256, 40, 60]               0\n     UpsampBlock-155          [-1, 256, 40, 60]               0\n ConvTranspose2d-156         [-1, 128, 80, 120]         131,200\n            ReLU-157         [-1, 256, 80, 120]               0\n     BatchNorm2d-158         [-1, 256, 80, 120]             512\nAdaptiveAvgPool2d-159            [-1, 256, 1, 1]               0\n          Linear-160                  [-1, 128]          32,896\n            ReLU-161                  [-1, 128]               0\n          Linear-162                  [-1, 256]          33,024\n         Sigmoid-163                  [-1, 256]               0\n        CSEBlock-164         [-1, 256, 80, 120]               0\n          Conv2d-165           [-1, 1, 80, 120]             257\n         Sigmoid-166           [-1, 1, 80, 120]               0\n        SSEBlock-167         [-1, 256, 80, 120]               0\n       SCSEBlock-168         [-1, 256, 80, 120]               0\n     UpsampBlock-169         [-1, 256, 80, 120]               0\n ConvTranspose2d-170        [-1, 128, 160, 240]         131,200\n            ReLU-171        [-1, 256, 160, 240]               0\n     BatchNorm2d-172        [-1, 256, 160, 240]             512\nAdaptiveAvgPool2d-173            [-1, 256, 1, 1]               0\n          Linear-174                  [-1, 128]          32,896\n            ReLU-175                  [-1, 128]               0\n          Linear-176                  [-1, 256]          33,024\n         Sigmoid-177                  [-1, 256]               0\n        CSEBlock-178        [-1, 256, 160, 240]               0\n          Conv2d-179          [-1, 1, 160, 240]             257\n         Sigmoid-180          [-1, 1, 160, 240]               0\n        SSEBlock-181        [-1, 256, 160, 240]               0\n       SCSEBlock-182        [-1, 256, 160, 240]               0\n     UpsampBlock-183        [-1, 256, 160, 240]               0\n ConvTranspose2d-184          [-1, 1, 320, 480]           1,025\n         Sigmoid-185          [-1, 1, 320, 480]               0\n================================================================\nTotal params: 22,537,029\nTrainable params: 22,537,029\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 1.76\nForward/backward pass size (MB): 995.73\nParams size (MB): 85.97\nEstimated Total Size (MB): 1083.46\n----------------------------------------------------------------\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00002-ee16a739-e3a0-4689-a9ed-33c171733c59",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 3,
        "output_cleared": true,
        "source_hash": "fff36fea",
        "tags": [],
        "execution_start": 1618265234744,
        "deepnote_cell_type": "code"
      },
      "source": "# Make a pdf-image of the architecture\n# from torchviz import make_dot\n\n# x = torch.randn(1,3, 320, 480)\n# y = net(x) \n\n# make_dot(y).view()",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00008-2490e92f-e198-4476-b952-17b7f423f7e6",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "ca73ef79",
        "execution_millis": 1612,
        "output_cleared": false,
        "execution_start": 1618344939558,
        "deepnote_cell_type": "code"
      },
      "source": "def epoch_to_PIL(data_loader, network, device=torch.device(\"cpu\")) -> dict:\n    converted = {\"xs\": [], \"ys\": [], \"preds\": []}\n    for x_batch, y_batch in data_loader:\n        preds = network(x_batch)\n        converted[\"xs\"].extend(batch_to_PIL(x_batch))\n        converted[\"ys\"].extend(batch_to_PIL(y_batch))\n        converted[\"preds\"].extend(batch_to_PIL(preds))\n    return converted\n\n\ndef batch_to_PIL(tensor_batch) -> list:\n    converted = []\n    for t in tensor_batch:\n        img = transforms.ToPILImage()(t)\n        converted.append(img)\n    return converted\n\nnetwork = main.Net()\nmodel.load_state_dict(torch.load(\"model_parametersCFD.pt\"))#[\"params\"]\nmodel.eval()\n\npics = epoch_to_PIL(test_loader, network)\n\nsubplot(r,c) provide the no. of rows and columns\nn_examples = 10\nf, axarr = plt.subplots(n_examples,3, figsize=(15, n_examples*4)) \n\nfor i in range(n_examples):\n    axarr[i][0].imshow(pics[\"xs\"][i])\n    axarr[i][1].imshow(pics[\"ys\"][i])\n    axarr[i][2].imshow(pics[\"preds\"][i])\n",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "dataset len: 118\ndataset: 118, objects_train: 71, BS_train: 10, dataloader len: 8\nobjects_test: 47, BS_test: 47, dataloader len: 1\n",
          "output_type": "stream"
        },
        {
          "output_type": "error",
          "ename": "KernelInterrupted",
          "evalue": "Execution interrupted by the Jupyter kernel.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKernelInterrupted\u001b[0m: Execution interrupted by the Jupyter kernel."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=411d58e9-cb4b-4924-bef0-2f383eff0187' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "tags": [],
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 4,
  "metadata": {
    "deepnote": {
      "is_reactive": false
    },
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "96775278-d606-4bc7-a96c-64fcdaf37c69",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  }
}