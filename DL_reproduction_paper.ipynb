{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Reproduce DL\n",
    "## Automated Pavement Crack Segmentation\n",
    "\n",
    "We start by setting up the actual Architecture. This means making sure all weights are properly initialized and all layers are connected. \n",
    "\n",
    "We make use of PyTorch for the implementation.\n",
    "\n",
    "Multiple parts come together (A U-based ResNet);\n",
    "- We recreate ResNet34 and remove the last two layers\n",
    "- We made sure that a ResNet-block is either 4 or 6 layers depending on if stride is not 1 (which in our case always happens when the in_channels are not equal to out_channels)\n",
    "- We use transfer learning such that the ResNet34 parameters are initialized as if trained on ImageNet\n",
    "- We create Squeeze and Excitation blocks that are applied per Channel (cSE) and per Spatial (sSE) (image)\n",
    "- These two blocks are combined (scSE) and then the maximum of this is taken\n",
    "- Each convolutional layer its parameters are initialized via \"He Kaiming\" method."
   ],
   "metadata": {
    "cell_id": "00000-82d331e0-79e4-40f0-ba43-0ad2ccc7fea5",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00001-7e91ba22-24c3-47de-a4fc-1812208e0fff",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "7bddc963",
    "execution_millis": 4261,
    "output_cleared": true,
    "execution_start": 1618392447957,
    "deepnote_cell_type": "code"
   },
   "source": [
    "# Do all the imports\n",
    "## Packages\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from torchsummary import summary\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "## Project\n",
    "from architecture import main\n",
    "from loss.loss import batch_dice_loss\n",
    "from utils.layers import layer_split\n",
    "from utils.retrieve_device import try_gpu\n",
    "from utils.dataset import get_data_loaders\n",
    "from evaluation.binary_classification import get_prec_recall, get_f1"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00004-a65cc30d-dddc-41df-9d94-28845042d191",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1958,
    "output_cleared": true,
    "source_hash": null,
    "tags": [],
    "execution_start": 1617360992742,
    "deepnote_cell_type": "code"
   },
   "source": [
    "# Always needs to be a factor of 3\n",
    "# Phase 1 = 1/3 time, Phase 2 = 2/3 time\n",
    "EPOCHS = 90\n",
    "epochs_1 = ( EPOCHS // 3 )\n",
    "epochs_2 = ( EPOCHS // 3 ) * 2\n",
    "\n",
    "# Define list to store losses and performances of each interation\n",
    "metrics = []\n",
    "\n",
    "# Try using gpu\n",
    "device = try_gpu()\n",
    "\n",
    "#Initialize network\n",
    "network = main.Net()\n",
    "\n",
    "#Initiliaze loss function\n",
    "criterion = batch_dice_loss\n",
    "\n",
    "# Split layers into three, for seperate optimization\n",
    "layer_1, layer_2, layer_3 = layer_split(network)\n",
    "datasetname = \"CFD\"\n",
    "\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {'params': layer_1, 'name': 'layer_1'},\n",
    "    {'params': layer_2, 'name': 'layer_2'},\n",
    "    {'params': layer_3, 'name': 'layer_3'}], betas=(0.9, 0.999), weight_decay = 0.01)\n",
    "\n",
    "# Image factor explanation:\n",
    "# 1 = 320\n",
    "# 0.8 = 256\n",
    "# 0.4 = 128\n",
    "split_seed = 42\n",
    "\n",
    "# Get dataloaders (128x128)\n",
    "dataset, train_loader, test_loader = get_data_loaders(split_seed, 0.4, datasetname)\n",
    "\n",
    "# Look at this more carefully\n",
    "# it should do this:\n",
    "# - max lr is 1.0\n",
    "# - start at 5% (0.05) of max_lr \n",
    "# - linearly build up\n",
    "# - max_lr at (total_epoch * 0.4)\n",
    "# - linearly break down\n",
    "# - end at 0.00005 lr at last epoch\n",
    "# Three phase: \n",
    "# - Up from initial to max,\n",
    "# - Down from max to initial,\n",
    "# - Down from initial to minimum\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=1.0,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    anneal_strategy='linear',\n",
    "    pct_start=0.4, \n",
    "    div_factor=20,\n",
    "    final_div_factor=20000,\n",
    "    three_phase=True\n",
    "    )\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    # Network in training mode and to device\n",
    "    network.train()\n",
    "    network.to(device)\n",
    "    \n",
    "    optimizer.param_groups[0][\"lr\"] = 0 if epoch < epochs_1 else optimizer.param_groups[2][\"lr\"] / 9\n",
    "    optimizer.param_groups[1][\"lr\"] = optimizer.param_groups[2][\"lr\"] / 3\n",
    "\n",
    "    print(f\"epoch: {epoch+1}, lr_layer_3 = {optimizer.param_groups[2]['lr']}\")\n",
    "    \n",
    "    if (epoch == epochs_1):\n",
    "        # Get dataloaders (256x256)\n",
    "        dataset, train_loader, test_loader = get_data_loaders(0.8, datasetname)\n",
    "\n",
    "    if (epoch == epochs_2):\n",
    "        # Get dataloaders (320x320)\n",
    "        dataset, train_loader, test_loader = get_data_loaders(1, datasetname)\n",
    "\n",
    "    # Training loop\n",
    "    for i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "\n",
    "        # Set to same device\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        # Set the gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform forward pass\n",
    "        y_pred = network(x_batch)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "\n",
    "        # Backward computation and update\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "    # Compute precision, recall, and f1 for train and test data\n",
    "    if epoch >= EPOCHS - 3:\n",
    "        train_prec, train_recall = get_prec_recall(train_loader, network.to(\"cpu\"))\n",
    "        train_f1 = get_f1(train_prec, train_recall)\n",
    "        test_prec, test_recall = get_prec_recall(test_loader, network.to(\"cpu\"))\n",
    "        test_f1 = get_f1(test_prec, test_recall)\n",
    "        metrics.append([train_prec, train_recall, train_f1, test_prec, test_recall, test_f1, loss.tolist()])\n",
    "\n",
    "        # Print performance\n",
    "        print('Epoch: {:.0f}'.format(epoch+1))\n",
    "        print(f'Precision, Recall, and F1 of train set: {train_prec}, {train_recall}, {train_f1}')\n",
    "        print(f'Precision, Recall, and F1 of test set: {test_prec}, {test_recall}, {test_f1}')\n",
    "        print('')\n",
    "\n",
    "\n",
    "# Save model\n",
    "model_state = network.state_dict()\n",
    "reproduction_info = { \"params\": model_state, \"split_seed\": split_seed }\n",
    "torch.save(model_state, \"model_parameters.pt\")\n",
    "\n",
    "# Write metrics to disk\n",
    "df = pd.DataFrame(metrics, columns=[\n",
    "    \"train_prec\", \"train_recall\", \"train_f1\", \"test_prec\", \"test_recall\", \"test_f1\", \"loss\"])\n",
    "df.to_csv(\"metrics.csv\", index=False)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00009-33ee83a7-ab83-4eb4-811f-2dc28934f96d",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "89401f6a",
    "execution_millis": 4528,
    "execution_start": 1618344919590,
    "deepnote_cell_type": "code"
   },
   "source": [
    "# Summarize the Architecture as output\n",
    "network = main.Net()\n",
    "device = try_gpu()\n",
    "model = network.to(device)\n",
    "\n",
    "# print(network)\n",
    "summary(model, input_size=(3, 320, 480))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1         [-1, 64, 160, 240]           9,408\n       BatchNorm2d-2         [-1, 64, 160, 240]             128\n              ReLU-3         [-1, 64, 160, 240]               0\n            Conv2d-4        [-1, 128, 160, 240]           8,320\n         MaxPool2d-5          [-1, 64, 80, 120]               0\n            Conv2d-6          [-1, 64, 80, 120]          36,864\n       BatchNorm2d-7          [-1, 64, 80, 120]             128\n              ReLU-8          [-1, 64, 80, 120]               0\n            Conv2d-9          [-1, 64, 80, 120]          36,864\n      BatchNorm2d-10          [-1, 64, 80, 120]             128\n             ReLU-11          [-1, 64, 80, 120]               0\n         ResBlock-12          [-1, 64, 80, 120]               0\n           Conv2d-13          [-1, 64, 80, 120]          36,864\n      BatchNorm2d-14          [-1, 64, 80, 120]             128\n             ReLU-15          [-1, 64, 80, 120]               0\n           Conv2d-16          [-1, 64, 80, 120]          36,864\n      BatchNorm2d-17          [-1, 64, 80, 120]             128\n             ReLU-18          [-1, 64, 80, 120]               0\n         ResBlock-19          [-1, 64, 80, 120]               0\n           Conv2d-20          [-1, 64, 80, 120]          36,864\n      BatchNorm2d-21          [-1, 64, 80, 120]             128\n             ReLU-22          [-1, 64, 80, 120]               0\n           Conv2d-23          [-1, 64, 80, 120]          36,864\n      BatchNorm2d-24          [-1, 64, 80, 120]             128\n             ReLU-25          [-1, 64, 80, 120]               0\n         ResBlock-26          [-1, 64, 80, 120]               0\n           Conv2d-27         [-1, 128, 80, 120]           8,320\n           Conv2d-28          [-1, 128, 40, 60]          73,728\n      BatchNorm2d-29          [-1, 128, 40, 60]             256\n             ReLU-30          [-1, 128, 40, 60]               0\n           Conv2d-31          [-1, 128, 40, 60]         147,456\n      BatchNorm2d-32          [-1, 128, 40, 60]             256\n           Conv2d-33          [-1, 128, 40, 60]           8,192\n      BatchNorm2d-34          [-1, 128, 40, 60]             256\n             ReLU-35          [-1, 128, 40, 60]               0\n         ResBlock-36          [-1, 128, 40, 60]               0\n           Conv2d-37          [-1, 128, 40, 60]         147,456\n      BatchNorm2d-38          [-1, 128, 40, 60]             256\n             ReLU-39          [-1, 128, 40, 60]               0\n           Conv2d-40          [-1, 128, 40, 60]         147,456\n      BatchNorm2d-41          [-1, 128, 40, 60]             256\n             ReLU-42          [-1, 128, 40, 60]               0\n         ResBlock-43          [-1, 128, 40, 60]               0\n           Conv2d-44          [-1, 128, 40, 60]         147,456\n      BatchNorm2d-45          [-1, 128, 40, 60]             256\n             ReLU-46          [-1, 128, 40, 60]               0\n           Conv2d-47          [-1, 128, 40, 60]         147,456\n      BatchNorm2d-48          [-1, 128, 40, 60]             256\n             ReLU-49          [-1, 128, 40, 60]               0\n         ResBlock-50          [-1, 128, 40, 60]               0\n           Conv2d-51          [-1, 128, 40, 60]         147,456\n      BatchNorm2d-52          [-1, 128, 40, 60]             256\n             ReLU-53          [-1, 128, 40, 60]               0\n           Conv2d-54          [-1, 128, 40, 60]         147,456\n      BatchNorm2d-55          [-1, 128, 40, 60]             256\n             ReLU-56          [-1, 128, 40, 60]               0\n         ResBlock-57          [-1, 128, 40, 60]               0\n           Conv2d-58          [-1, 128, 40, 60]          16,512\n           Conv2d-59          [-1, 256, 20, 30]         294,912\n      BatchNorm2d-60          [-1, 256, 20, 30]             512\n             ReLU-61          [-1, 256, 20, 30]               0\n           Conv2d-62          [-1, 256, 20, 30]         589,824\n      BatchNorm2d-63          [-1, 256, 20, 30]             512\n           Conv2d-64          [-1, 256, 20, 30]          32,768\n      BatchNorm2d-65          [-1, 256, 20, 30]             512\n             ReLU-66          [-1, 256, 20, 30]               0\n         ResBlock-67          [-1, 256, 20, 30]               0\n           Conv2d-68          [-1, 256, 20, 30]         589,824\n      BatchNorm2d-69          [-1, 256, 20, 30]             512\n             ReLU-70          [-1, 256, 20, 30]               0\n           Conv2d-71          [-1, 256, 20, 30]         589,824\n      BatchNorm2d-72          [-1, 256, 20, 30]             512\n             ReLU-73          [-1, 256, 20, 30]               0\n         ResBlock-74          [-1, 256, 20, 30]               0\n           Conv2d-75          [-1, 256, 20, 30]         589,824\n      BatchNorm2d-76          [-1, 256, 20, 30]             512\n             ReLU-77          [-1, 256, 20, 30]               0\n           Conv2d-78          [-1, 256, 20, 30]         589,824\n      BatchNorm2d-79          [-1, 256, 20, 30]             512\n             ReLU-80          [-1, 256, 20, 30]               0\n         ResBlock-81          [-1, 256, 20, 30]               0\n           Conv2d-82          [-1, 256, 20, 30]         589,824\n      BatchNorm2d-83          [-1, 256, 20, 30]             512\n             ReLU-84          [-1, 256, 20, 30]               0\n           Conv2d-85          [-1, 256, 20, 30]         589,824\n      BatchNorm2d-86          [-1, 256, 20, 30]             512\n             ReLU-87          [-1, 256, 20, 30]               0\n         ResBlock-88          [-1, 256, 20, 30]               0\n           Conv2d-89          [-1, 256, 20, 30]         589,824\n      BatchNorm2d-90          [-1, 256, 20, 30]             512\n             ReLU-91          [-1, 256, 20, 30]               0\n           Conv2d-92          [-1, 256, 20, 30]         589,824\n      BatchNorm2d-93          [-1, 256, 20, 30]             512\n             ReLU-94          [-1, 256, 20, 30]               0\n         ResBlock-95          [-1, 256, 20, 30]               0\n           Conv2d-96          [-1, 256, 20, 30]         589,824\n      BatchNorm2d-97          [-1, 256, 20, 30]             512\n             ReLU-98          [-1, 256, 20, 30]               0\n           Conv2d-99          [-1, 256, 20, 30]         589,824\n     BatchNorm2d-100          [-1, 256, 20, 30]             512\n            ReLU-101          [-1, 256, 20, 30]               0\n        ResBlock-102          [-1, 256, 20, 30]               0\n          Conv2d-103          [-1, 128, 20, 30]          32,896\n          Conv2d-104          [-1, 512, 10, 15]       1,179,648\n     BatchNorm2d-105          [-1, 512, 10, 15]           1,024\n            ReLU-106          [-1, 512, 10, 15]               0\n          Conv2d-107          [-1, 512, 10, 15]       2,359,296\n     BatchNorm2d-108          [-1, 512, 10, 15]           1,024\n          Conv2d-109          [-1, 512, 10, 15]         131,072\n     BatchNorm2d-110          [-1, 512, 10, 15]           1,024\n            ReLU-111          [-1, 512, 10, 15]               0\n        ResBlock-112          [-1, 512, 10, 15]               0\n          Conv2d-113          [-1, 512, 10, 15]       2,359,296\n     BatchNorm2d-114          [-1, 512, 10, 15]           1,024\n            ReLU-115          [-1, 512, 10, 15]               0\n          Conv2d-116          [-1, 512, 10, 15]       2,359,296\n     BatchNorm2d-117          [-1, 512, 10, 15]           1,024\n            ReLU-118          [-1, 512, 10, 15]               0\n        ResBlock-119          [-1, 512, 10, 15]               0\n          Conv2d-120          [-1, 512, 10, 15]       2,359,296\n     BatchNorm2d-121          [-1, 512, 10, 15]           1,024\n            ReLU-122          [-1, 512, 10, 15]               0\n          Conv2d-123          [-1, 512, 10, 15]       2,359,296\n     BatchNorm2d-124          [-1, 512, 10, 15]           1,024\n            ReLU-125          [-1, 512, 10, 15]               0\n        ResBlock-126          [-1, 512, 10, 15]               0\n          Conv2d-127          [-1, 512, 10, 15]         262,656\n ConvTranspose2d-128          [-1, 128, 20, 30]         262,272\n            ReLU-129          [-1, 256, 20, 30]               0\n     BatchNorm2d-130          [-1, 256, 20, 30]             512\nAdaptiveAvgPool2d-131            [-1, 256, 1, 1]               0\n          Linear-132                  [-1, 128]          32,896\n            ReLU-133                  [-1, 128]               0\n          Linear-134                  [-1, 256]          33,024\n         Sigmoid-135                  [-1, 256]               0\n        CSEBlock-136          [-1, 256, 20, 30]               0\n          Conv2d-137            [-1, 1, 20, 30]             257\n         Sigmoid-138            [-1, 1, 20, 30]               0\n        SSEBlock-139          [-1, 256, 20, 30]               0\n       SCSEBlock-140          [-1, 256, 20, 30]               0\n     UpsampBlock-141          [-1, 256, 20, 30]               0\n ConvTranspose2d-142          [-1, 128, 40, 60]         131,200\n            ReLU-143          [-1, 256, 40, 60]               0\n     BatchNorm2d-144          [-1, 256, 40, 60]             512\nAdaptiveAvgPool2d-145            [-1, 256, 1, 1]               0\n          Linear-146                  [-1, 128]          32,896\n            ReLU-147                  [-1, 128]               0\n          Linear-148                  [-1, 256]          33,024\n         Sigmoid-149                  [-1, 256]               0\n        CSEBlock-150          [-1, 256, 40, 60]               0\n          Conv2d-151            [-1, 1, 40, 60]             257\n         Sigmoid-152            [-1, 1, 40, 60]               0\n        SSEBlock-153          [-1, 256, 40, 60]               0\n       SCSEBlock-154          [-1, 256, 40, 60]               0\n     UpsampBlock-155          [-1, 256, 40, 60]               0\n ConvTranspose2d-156         [-1, 128, 80, 120]         131,200\n            ReLU-157         [-1, 256, 80, 120]               0\n     BatchNorm2d-158         [-1, 256, 80, 120]             512\nAdaptiveAvgPool2d-159            [-1, 256, 1, 1]               0\n          Linear-160                  [-1, 128]          32,896\n            ReLU-161                  [-1, 128]               0\n          Linear-162                  [-1, 256]          33,024\n         Sigmoid-163                  [-1, 256]               0\n        CSEBlock-164         [-1, 256, 80, 120]               0\n          Conv2d-165           [-1, 1, 80, 120]             257\n         Sigmoid-166           [-1, 1, 80, 120]               0\n        SSEBlock-167         [-1, 256, 80, 120]               0\n       SCSEBlock-168         [-1, 256, 80, 120]               0\n     UpsampBlock-169         [-1, 256, 80, 120]               0\n ConvTranspose2d-170        [-1, 128, 160, 240]         131,200\n            ReLU-171        [-1, 256, 160, 240]               0\n     BatchNorm2d-172        [-1, 256, 160, 240]             512\nAdaptiveAvgPool2d-173            [-1, 256, 1, 1]               0\n          Linear-174                  [-1, 128]          32,896\n            ReLU-175                  [-1, 128]               0\n          Linear-176                  [-1, 256]          33,024\n         Sigmoid-177                  [-1, 256]               0\n        CSEBlock-178        [-1, 256, 160, 240]               0\n          Conv2d-179          [-1, 1, 160, 240]             257\n         Sigmoid-180          [-1, 1, 160, 240]               0\n        SSEBlock-181        [-1, 256, 160, 240]               0\n       SCSEBlock-182        [-1, 256, 160, 240]               0\n     UpsampBlock-183        [-1, 256, 160, 240]               0\n ConvTranspose2d-184          [-1, 1, 320, 480]           1,025\n         Sigmoid-185          [-1, 1, 320, 480]               0\n================================================================\nTotal params: 22,537,029\nTrainable params: 22,537,029\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 1.76\nForward/backward pass size (MB): 995.73\nParams size (MB): 85.97\nEstimated Total Size (MB): 1083.46\n----------------------------------------------------------------\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00008-2490e92f-e198-4476-b952-17b7f423f7e6",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "ca73ef79",
    "execution_millis": 1612,
    "output_cleared": false,
    "execution_start": 1618344939558,
    "deepnote_cell_type": "code"
   },
   "source": [
    "def epoch_to_PIL(data_loader, network, device=torch.device(\"cpu\")) -> dict:\n",
    "    converted = {\"xs\": [], \"ys\": [], \"preds\": []}\n",
    "    for x_batch, y_batch in data_loader:\n",
    "        preds = network(x_batch)\n",
    "        converted[\"xs\"].extend(batch_to_PIL(x_batch))\n",
    "        converted[\"ys\"].extend(batch_to_PIL(y_batch))\n",
    "        converted[\"preds\"].extend(batch_to_PIL(preds))\n",
    "    return converted\n",
    "\n",
    "\n",
    "def batch_to_PIL(tensor_batch) -> list:\n",
    "    converted = []\n",
    "    for t in tensor_batch:\n",
    "        img = transforms.ToPILImage()(t)\n",
    "        converted.append(img)\n",
    "    return converted\n",
    "\n",
    "network = main.Net()\n",
    "model.load_state_dict(torch.load(\"model_parametersCFD.pt\"))#[\"params\"]\n",
    "model.eval()\n",
    "\n",
    "pics = epoch_to_PIL(test_loader, network)\n",
    "\n",
    "subplot(r,c) # provide the no. of rows and columns\n",
    "n_examples = 10\n",
    "f, axarr = plt.subplots(n_examples,3, figsize=(15, n_examples*4)) \n",
    "\n",
    "for i in range(n_examples):\n",
    "    axarr[i][0].imshow(pics[\"xs\"][i])\n",
    "    axarr[i][1].imshow(pics[\"ys\"][i])\n",
    "    axarr[i][2].imshow(pics[\"preds\"][i])\n"
   ],
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "dataset len: 118\ndataset: 118, objects_train: 71, BS_train: 10, dataloader len: 8\nobjects_test: 47, BS_test: 47, dataloader len: 1\n",
     "output_type": "stream"
    },
    {
     "output_type": "error",
     "ename": "KernelInterrupted",
     "evalue": "Execution interrupted by the Jupyter kernel.",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKernelInterrupted\u001B[0m: Execution interrupted by the Jupyter kernel."
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=411d58e9-cb4b-4924-bef0-2f383eff0187' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz4KPHN2ZyB3aWR0aD0iODBweCIgaGVpZ2h0PSI4MHB4IiB2aWV3Qm94PSIwIDAgODAgODAiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayI+CiAgICA8IS0tIEdlbmVyYXRvcjogU2tldGNoIDU0LjEgKDc2NDkwKSAtIGh0dHBzOi8vc2tldGNoYXBwLmNvbSAtLT4KICAgIDx0aXRsZT5Hcm91cCAzPC90aXRsZT4KICAgIDxkZXNjPkNyZWF0ZWQgd2l0aCBTa2V0Y2guPC9kZXNjPgogICAgPGcgaWQ9IkxhbmRpbmciIHN0cm9rZT0ibm9uZSIgc3Ryb2tlLXdpZHRoPSIxIiBmaWxsPSJub25lIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiPgogICAgICAgIDxnIGlkPSJBcnRib2FyZCIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoLTEyMzUuMDAwMDAwLCAtNzkuMDAwMDAwKSI+CiAgICAgICAgICAgIDxnIGlkPSJHcm91cC0zIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSgxMjM1LjAwMDAwMCwgNzkuMDAwMDAwKSI+CiAgICAgICAgICAgICAgICA8cG9seWdvbiBpZD0iUGF0aC0yMCIgZmlsbD0iIzAyNjVCNCIgcG9pbnRzPSIyLjM3NjIzNzYyIDgwIDM4LjA0NzY2NjcgODAgNTcuODIxNzgyMiA3My44MDU3NTkyIDU3LjgyMTc4MjIgMzIuNzU5MjczOSAzOS4xNDAyMjc4IDMxLjY4MzE2ODMiPjwvcG9seWdvbj4KICAgICAgICAgICAgICAgIDxwYXRoIGQ9Ik0zNS4wMDc3MTgsODAgQzQyLjkwNjIwMDcsNzYuNDU0OTM1OCA0Ny41NjQ5MTY3LDcxLjU0MjI2NzEgNDguOTgzODY2LDY1LjI2MTk5MzkgQzUxLjExMjI4OTksNTUuODQxNTg0MiA0MS42NzcxNzk1LDQ5LjIxMjIyODQgMjUuNjIzOTg0Niw0OS4yMTIyMjg0IEMyNS40ODQ5Mjg5LDQ5LjEyNjg0NDggMjkuODI2MTI5Niw0My4yODM4MjQ4IDM4LjY0NzU4NjksMzEuNjgzMTY4MyBMNzIuODcxMjg3MSwzMi41NTQ0MjUgTDY1LjI4MDk3Myw2Ny42NzYzNDIxIEw1MS4xMTIyODk5LDc3LjM3NjE0NCBMMzUuMDA3NzE4LDgwIFoiIGlkPSJQYXRoLTIyIiBmaWxsPSIjMDAyODY4Ij48L3BhdGg+CiAgICAgICAgICAgICAgICA8cGF0aCBkPSJNMCwzNy43MzA0NDA1IEwyNy4xMTQ1MzcsMC4yNTcxMTE0MzYgQzYyLjM3MTUxMjMsLTEuOTkwNzE3MDEgODAsMTAuNTAwMzkyNyA4MCwzNy43MzA0NDA1IEM4MCw2NC45NjA0ODgyIDY0Ljc3NjUwMzgsNzkuMDUwMzQxNCAzNC4zMjk1MTEzLDgwIEM0Ny4wNTUzNDg5LDc3LjU2NzA4MDggNTMuNDE4MjY3Nyw3MC4zMTM2MTAzIDUzLjQxODI2NzcsNTguMjM5NTg4NSBDNTMuNDE4MjY3Nyw0MC4xMjg1NTU3IDM2LjMwMzk1NDQsMzcuNzMwNDQwNSAyNS4yMjc0MTcsMzcuNzMwNDQwNSBDMTcuODQzMDU4NiwzNy43MzA0NDA1IDkuNDMzOTE5NjYsMzcuNzMwNDQwNSAwLDM3LjczMDQ0MDUgWiIgaWQ9IlBhdGgtMTkiIGZpbGw9IiMzNzkzRUYiPjwvcGF0aD4KICAgICAgICAgICAgPC9nPgogICAgICAgIDwvZz4KICAgIDwvZz4KPC9zdmc+' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 4,
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "96775278-d606-4bc7-a96c-64fcdaf37c69",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 }
}