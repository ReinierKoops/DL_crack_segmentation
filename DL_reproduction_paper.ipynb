{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Reproduce DL\n## Automated Pavement Crack Segmentation\n\nWe start by setting up the actual Architecture. This means making sure all weights are properly initialized and all layers are connected. \n\nWe make use of PyTorch for the implementation.\n\nMultiple parts come together (A U-based ResNet);\n- We recreate ResNet34 and remove the last two layers\n- We made sure that a ResNet-block is either 4 or 6 layers depending on if stride is not 1 (which in our case always happens when the in_channels are not equal to out_channels)\n- We use transfer learning such that the ResNet34 parameters are initialized as if trained on ImageNet\n- We create Squeeze and Excitation blocks that are applied per Channel (cSE) and per Spatial (sSE) (image)\n- These two blocks are combined (scSE) and then the maximum of this is taken\n- Each convolutional layer its parameters are initialized via \"He Kaiming\" method.",
      "metadata": {
        "cell_id": "00000-82d331e0-79e4-40f0-ba43-0ad2ccc7fea5",
        "tags": [],
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00002-da764467-46fa-4b0b-8c70-b51631d8659f",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 3685,
        "source_hash": "9def676a",
        "tags": [
          "outputPrepend"
        ],
        "execution_start": 1616766637272,
        "deepnote_cell_type": "code"
      },
      "source": "from architecture import main\nfrom torchsummary import summary\n\nnetwork = main.Net()\nprint(network)\n# summary(network, input_size=(3, 320, 480))",
      "execution_count": 2,
      "outputs": [
        {
          "name": "stderr",
          "text": "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n",
          "output_type": "stream"
        },
        {
          "data": {
            "text/plain": "  0%|          | 0.00/83.3M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3998ebac7e644aa6befde9b1a19ea88c"
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "text": "Net(\n  (blueBlock): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n  )\n  (resBlock1): Sequential(\n    (0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (1): Sequential(\n      (0): ResBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): ResBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): ResBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (resBlock2): Sequential(\n    (0): Sequential(\n      (0): ResBlock(\n        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): ResBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): ResBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (3): ResBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (resBlock3): Sequential(\n    (0): Sequential(\n      (0): ResBlock(\n        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): ResBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): ResBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (3): ResBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (4): ResBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (5): ResBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (resBlock4): Sequential(\n    (0): Sequential(\n      (0): ResBlock(\n        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): ResBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): ResBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (conv_blue_to_yel): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n  (conv_gr_to_yel_1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n  (conv_gr_to_yel_2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n  (conv_gr_to_yel_3): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n  (conv_gr_to_purp): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n  (conv_mag_to_purp_1): UpsampBlock(\n    (relu): ReLU(inplace=True)\n    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (scse): SCSEBlock(\n      (CSE): CSEBlock(\n        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n        (fc1): Linear(in_features=256, out_features=128, bias=True)\n        (relu): ReLU(inplace=True)\n        (fc2): Linear(in_features=128, out_features=256, bias=True)\n        (sigmoid): Sigmoid()\n      )\n      (SSE): SSEBlock(\n        (conv): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n        (sigmoid): Sigmoid()\n      )\n    )\n  )\n  (conv_mag_to_purp_2): UpsampBlock(\n    (relu): ReLU(inplace=True)\n    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (scse): SCSEBlock(\n      (CSE): CSEBlock(\n        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n        (fc1): Linear(in_features=256, out_features=128, bias=True)\n        (relu): ReLU(inplace=True)\n        (fc2): Linear(in_features=128, out_features=256, bias=True)\n        (sigmoid): Sigmoid()\n      )\n      (SSE): SSEBlock(\n        (conv): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n        (sigmoid): Sigmoid()\n      )\n    )\n  )\n  (conv_mag_to_purp_3): UpsampBlock(\n    (relu): ReLU(inplace=True)\n    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (scse): SCSEBlock(\n      (CSE): CSEBlock(\n        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n        (fc1): Linear(in_features=256, out_features=128, bias=True)\n        (relu): ReLU(inplace=True)\n        (fc2): Linear(in_features=128, out_features=256, bias=True)\n        (sigmoid): Sigmoid()\n      )\n      (SSE): SSEBlock(\n        (conv): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n        (sigmoid): Sigmoid()\n      )\n    )\n  )\n  (conv_mag_to_purp_4): UpsampBlock(\n    (relu): ReLU(inplace=True)\n    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (scse): SCSEBlock(\n      (CSE): CSEBlock(\n        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n        (fc1): Linear(in_features=256, out_features=128, bias=True)\n        (relu): ReLU(inplace=True)\n        (fc2): Linear(in_features=128, out_features=256, bias=True)\n        (sigmoid): Sigmoid()\n      )\n      (SSE): SSEBlock(\n        (conv): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n        (sigmoid): Sigmoid()\n      )\n    )\n  )\n  (conv_purp_to_mag_1): ConvTranspose2d(512, 128, kernel_size=(2, 2), stride=(2, 2))\n  (conv_purp_to_mag_2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n  (conv_purp_to_mag_3): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n  (conv_purp_to_mag_4): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n  (conv_purp_to_mag_5): ConvTranspose2d(256, 1, kernel_size=(2, 2), stride=(2, 2))\n)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00002-0c6e2e3b-db59-4681-ab21-9c6526eb0f05",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 5,
        "execution_start": 1616745886878,
        "source_hash": "aba374a4",
        "deepnote_cell_type": "code"
      },
      "source": "import os\nimport torch\nfrom torch.utils.data import random_split\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\nfrom datasets.CFD.CFDdata import CFD\n\ncurrent_path = os.path.abspath(os.getcwd())\n\ntotensor = transforms.ToTensor()\ndataset = CFD(current_path + \"/datasets/CFD/cfd_image/\", totensor, current_path + \"/datasets/CFD/seg_gt/\", totensor)\ngen = torch.Generator().manual_seed(42)\n\ntrain_data, test_data = random_split(dataset, [71, 47], gen)\ntrain_loader = DataLoader(train_data, batch_size=10)\ntest_loader = DataLoader(test_data, batch_size=47)\n\nprint(\"The current dataset is size: \", len(dataset), \n\"\\nThe current split is train/test: \", len(train_loader.dataset), \"/\", len(test_loader.dataset))\n\n\n# fig, axs = plt.subplots(5, 5, figsize=(5, 5))\n# for i in range(25):\n#     _, gt = test_data[i]\n#     ax = axs[i // 5][i % 5]\n#     ax.imshow(gt.view(320, 480), cmap=\"gray\")\n#     ax.axis(\"off\")\n# plt.tight_layout()\n# plt.show()",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "The current dataset is size:  118 \nThe current split is train/test:  71 / 47\n"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00004-7428292d-49f2-411d-8364-8347593a3c9e",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 68,
        "execution_start": 1616684409029,
        "source_hash": "d3235d1a",
        "tags": [],
        "deepnote_cell_type": "code"
      },
      "source": "# Some functions used during training\n\ndef try_gpu():\n    \"\"\"\n    If GPU is available, return torch.device as cuda:0; else return torch.device\n    as cpu.\n    \"\"\"\n    if torch.cuda.is_available():\n        device = torch.device('cuda:0')\n    else:\n        device = torch.device('cpu')\n    return device\n\n\ndef evaluate_accuracy(data_loader, network, device=torch.device('cpu')):\n    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n    network.eval()  #make sure network is in evaluation mode\n\n    #init\n    acc_sum = torch.tensor([0], dtype=torch.float32, device=device)\n    n = 0\n\n    for X, y in data_loader:\n        # Copy the data to device.\n        X, y = X.to(device), y.to(device)\n        with torch.no_grad():\n            y = y.long()\n            acc_sum += torch.sum((torch.argmax(network(X), dim=1) == y))\n            n += y.shape[0] #increases with the number of samples in the batch\n    return acc_sum.item()/n\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00004-a65cc30d-dddc-41df-9d94-28845042d191",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 45,
        "execution_start": 1616684471202,
        "output_cleared": true,
        "source_hash": null,
        "tags": [],
        "deepnote_cell_type": "code"
      },
      "source": "from loss import dice_loss\n\n\nfrom collections import OrderedDict\n\n# Tuning the learning rates\n# Split into three groups of layers, to have three different learning rates\nlayer_1 = OrderedDict()\nlayer_2 = OrderedDict()\nlayer_3 = OrderedDict()\nlayer_1_to_include = [\n    \"blueBlock\",\n    \"resBlock1\",\n    \"resBlock2\"\n    ]\nlayer_2_to_include = [\n    \"resBlock3\", \n    \"resBlock4\"\n    ]\n\nfor name, param in network.named_parameters():\n    if any(substring in name for substring in layer_1_to_include):\n        layer_1[name] = param\n    elif any(substring in name for substring in layer_2_to_include):\n        layer_1[name] = param\n    else:\n        layer_3[name] = param\n\n\n# training parameters\nlr = 1e-3\nepochs = 1\n\n#Initialize network\nnetwork = main.Net()\noptimizer = torch.optim.AdamW(network.parameters(), lr=lr, betas=(0.9, 0.999))\ncriterion = dice_loss.batch_dice_loss\n\n# Define list to store losses and performances of each interation\ntrain_losses = []\ntrain_accs = []\ntest_accs = []\n\n# Try using gpu instead of cpu\ndevice = try_gpu()\n\nfor epoch in range(epochs):\n\n    # Network in training mode and to device\n    network.train()\n    network.to(device)\n\n    # Training loop\n    for i, (x_batch, y_batch) in enumerate(train_loader):\n\n         # Set to same device\n         x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n\n         # Set the gradients to zero\n         optimizer.zero_grad()\n\n         # Perform forward pass\n         y_pred = network(x_batch)\n\n         # Compute the loss\n         loss = criterion(y_pred, y_batch)\n         train_losses.append(loss)\n\n         # Backward computation and update\n         loss.backward()\n         optimizer.step()\n    \n    # Compute train and test error\n    train_acc = 100*evaluate_accuracy(train_loader, network.to(device), device=device)\n    test_acc = 100*evaluate_accuracy(test_loader, network.to(device), device=device)\n    \n    # Development of performance\n    train_accs.append(train_acc)\n    test_accs.append(test_acc)\n\n    # Print performance\n    print('Epoch: {:.0f}'.format(epoch+1))\n    print('Accuracy of train set: {:.00f}%'.format(train_acc))\n    print('Accuracy of test set: {:.00f}%'.format(test_acc))\n    print('')\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00002-ee16a739-e3a0-4689-a9ed-33c171733c59",
        "deepnote_to_be_reexecuted": true,
        "execution_millis": 1981,
        "output_cleared": true,
        "source_hash": null,
        "tags": [],
        "deepnote_cell_type": "code"
      },
      "source": "# from torchviz import make_dot\n\n# x = torch.randn(1,3, 320, 480)\n# y = net(x) \n\n# make_dot(y).view()",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=411d58e9-cb4b-4924-bef0-2f383eff0187' target=\"_blank\">\n<img style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "tags": [],
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 4,
  "metadata": {
    "deepnote": {},
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "96775278-d606-4bc7-a96c-64fcdaf37c69",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  }
}