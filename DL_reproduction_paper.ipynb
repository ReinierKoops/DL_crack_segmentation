{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Reproduce DL\n## Automated Pavement Crack Segmentation\n\nWe start by setting up the actual Architecture. This means making sure all weights are properly initialized and all layers are connected. \n\nWe make use of PyTorch for the implementation.\n\nMultiple parts come together (A U-based ResNet);\n- We recreate ResNet34 and remove the last two layers\n- We made sure that a ResNet-block is either 4 or 6 layers depending on if stride is not 1 (which in our case always happens when the in_channels are not equal to out_channels)\n- We use transfer learning such that the ResNet34 parameters are initialized as if trained on ImageNet\n- We create Squeeze and Excitation blocks that are applied per Channel (cSE) and per Spatial (sSE) (image)\n- These two blocks are combined (scSE) and then the maximum of this is taken\n- Each convolutional layer its parameters are initialized via \"He Kaiming\" method.",
   "metadata": {
    "tags": [],
    "cell_id": "00000-82d331e0-79e4-40f0-ba43-0ad2ccc7fea5",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00002-da764467-46fa-4b0b-8c70-b51631d8659f",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "750d6355",
    "execution_millis": 10648,
    "execution_start": 1616684405017,
    "deepnote_cell_type": "code"
   },
   "source": "from architecture import main\nfrom torchsummary import summary\n\nnetwork = main.Net()\n# print(network)\nsummary(network, input_size=(3, 320, 480))",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1         [-1, 64, 160, 240]           9,408\n            Conv2d-2         [-1, 64, 160, 240]           9,408\n       BatchNorm2d-3         [-1, 64, 160, 240]             128\n       BatchNorm2d-4         [-1, 64, 160, 240]             128\n              ReLU-5         [-1, 64, 160, 240]               0\n              ReLU-6         [-1, 64, 160, 240]               0\n            Conv2d-7        [-1, 128, 160, 240]           8,320\n         MaxPool2d-8          [-1, 64, 80, 120]               0\n         MaxPool2d-9          [-1, 64, 80, 120]               0\n           Conv2d-10          [-1, 64, 80, 120]          36,864\n           Conv2d-11          [-1, 64, 80, 120]          36,864\n      BatchNorm2d-12          [-1, 64, 80, 120]             128\n      BatchNorm2d-13          [-1, 64, 80, 120]             128\n             ReLU-14          [-1, 64, 80, 120]               0\n             ReLU-15          [-1, 64, 80, 120]               0\n           Conv2d-16          [-1, 64, 80, 120]          36,864\n           Conv2d-17          [-1, 64, 80, 120]          36,864\n      BatchNorm2d-18          [-1, 64, 80, 120]             128\n      BatchNorm2d-19          [-1, 64, 80, 120]             128\n             ReLU-20          [-1, 64, 80, 120]               0\n             ReLU-21          [-1, 64, 80, 120]               0\n         ResBlock-22          [-1, 64, 80, 120]               0\n         ResBlock-23          [-1, 64, 80, 120]               0\n           Conv2d-24          [-1, 64, 80, 120]          36,864\n           Conv2d-25          [-1, 64, 80, 120]          36,864\n      BatchNorm2d-26          [-1, 64, 80, 120]             128\n      BatchNorm2d-27          [-1, 64, 80, 120]             128\n             ReLU-28          [-1, 64, 80, 120]               0\n             ReLU-29          [-1, 64, 80, 120]               0\n           Conv2d-30          [-1, 64, 80, 120]          36,864\n           Conv2d-31          [-1, 64, 80, 120]          36,864\n      BatchNorm2d-32          [-1, 64, 80, 120]             128\n      BatchNorm2d-33          [-1, 64, 80, 120]             128\n             ReLU-34          [-1, 64, 80, 120]               0\n             ReLU-35          [-1, 64, 80, 120]               0\n         ResBlock-36          [-1, 64, 80, 120]               0\n         ResBlock-37          [-1, 64, 80, 120]               0\n           Conv2d-38          [-1, 64, 80, 120]          36,864\n           Conv2d-39          [-1, 64, 80, 120]          36,864\n      BatchNorm2d-40          [-1, 64, 80, 120]             128\n      BatchNorm2d-41          [-1, 64, 80, 120]             128\n             ReLU-42          [-1, 64, 80, 120]               0\n             ReLU-43          [-1, 64, 80, 120]               0\n           Conv2d-44          [-1, 64, 80, 120]          36,864\n           Conv2d-45          [-1, 64, 80, 120]          36,864\n      BatchNorm2d-46          [-1, 64, 80, 120]             128\n      BatchNorm2d-47          [-1, 64, 80, 120]             128\n             ReLU-48          [-1, 64, 80, 120]               0\n             ReLU-49          [-1, 64, 80, 120]               0\n         ResBlock-50          [-1, 64, 80, 120]               0\n         ResBlock-51          [-1, 64, 80, 120]               0\n           Conv2d-52         [-1, 128, 80, 120]           8,320\n           Conv2d-53          [-1, 128, 40, 60]          73,728\n           Conv2d-54          [-1, 128, 40, 60]          73,728\n      BatchNorm2d-55          [-1, 128, 40, 60]             256\n      BatchNorm2d-56          [-1, 128, 40, 60]             256\n             ReLU-57          [-1, 128, 40, 60]               0\n             ReLU-58          [-1, 128, 40, 60]               0\n           Conv2d-59          [-1, 128, 40, 60]         147,456\n           Conv2d-60          [-1, 128, 40, 60]         147,456\n      BatchNorm2d-61          [-1, 128, 40, 60]             256\n      BatchNorm2d-62          [-1, 128, 40, 60]             256\n           Conv2d-63          [-1, 128, 40, 60]           8,192\n           Conv2d-64          [-1, 128, 40, 60]           8,192\n      BatchNorm2d-65          [-1, 128, 40, 60]             256\n      BatchNorm2d-66          [-1, 128, 40, 60]             256\n             ReLU-67          [-1, 128, 40, 60]               0\n             ReLU-68          [-1, 128, 40, 60]               0\n         ResBlock-69          [-1, 128, 40, 60]               0\n         ResBlock-70          [-1, 128, 40, 60]               0\n           Conv2d-71          [-1, 128, 40, 60]         147,456\n           Conv2d-72          [-1, 128, 40, 60]         147,456\n      BatchNorm2d-73          [-1, 128, 40, 60]             256\n      BatchNorm2d-74          [-1, 128, 40, 60]             256\n             ReLU-75          [-1, 128, 40, 60]               0\n             ReLU-76          [-1, 128, 40, 60]               0\n           Conv2d-77          [-1, 128, 40, 60]         147,456\n           Conv2d-78          [-1, 128, 40, 60]         147,456\n      BatchNorm2d-79          [-1, 128, 40, 60]             256\n      BatchNorm2d-80          [-1, 128, 40, 60]             256\n             ReLU-81          [-1, 128, 40, 60]               0\n             ReLU-82          [-1, 128, 40, 60]               0\n         ResBlock-83          [-1, 128, 40, 60]               0\n         ResBlock-84          [-1, 128, 40, 60]               0\n           Conv2d-85          [-1, 128, 40, 60]         147,456\n           Conv2d-86          [-1, 128, 40, 60]         147,456\n      BatchNorm2d-87          [-1, 128, 40, 60]             256\n      BatchNorm2d-88          [-1, 128, 40, 60]             256\n             ReLU-89          [-1, 128, 40, 60]               0\n             ReLU-90          [-1, 128, 40, 60]               0\n           Conv2d-91          [-1, 128, 40, 60]         147,456\n           Conv2d-92          [-1, 128, 40, 60]         147,456\n      BatchNorm2d-93          [-1, 128, 40, 60]             256\n      BatchNorm2d-94          [-1, 128, 40, 60]             256\n             ReLU-95          [-1, 128, 40, 60]               0\n             ReLU-96          [-1, 128, 40, 60]               0\n         ResBlock-97          [-1, 128, 40, 60]               0\n         ResBlock-98          [-1, 128, 40, 60]               0\n           Conv2d-99          [-1, 128, 40, 60]         147,456\n          Conv2d-100          [-1, 128, 40, 60]         147,456\n     BatchNorm2d-101          [-1, 128, 40, 60]             256\n     BatchNorm2d-102          [-1, 128, 40, 60]             256\n            ReLU-103          [-1, 128, 40, 60]               0\n            ReLU-104          [-1, 128, 40, 60]               0\n          Conv2d-105          [-1, 128, 40, 60]         147,456\n          Conv2d-106          [-1, 128, 40, 60]         147,456\n     BatchNorm2d-107          [-1, 128, 40, 60]             256\n     BatchNorm2d-108          [-1, 128, 40, 60]             256\n            ReLU-109          [-1, 128, 40, 60]               0\n            ReLU-110          [-1, 128, 40, 60]               0\n        ResBlock-111          [-1, 128, 40, 60]               0\n        ResBlock-112          [-1, 128, 40, 60]               0\n          Conv2d-113          [-1, 128, 40, 60]          16,512\n          Conv2d-114          [-1, 256, 20, 30]         294,912\n          Conv2d-115          [-1, 256, 20, 30]         294,912\n     BatchNorm2d-116          [-1, 256, 20, 30]             512\n     BatchNorm2d-117          [-1, 256, 20, 30]             512\n            ReLU-118          [-1, 256, 20, 30]               0\n            ReLU-119          [-1, 256, 20, 30]               0\n          Conv2d-120          [-1, 256, 20, 30]         589,824\n          Conv2d-121          [-1, 256, 20, 30]         589,824\n     BatchNorm2d-122          [-1, 256, 20, 30]             512\n     BatchNorm2d-123          [-1, 256, 20, 30]             512\n          Conv2d-124          [-1, 256, 20, 30]          32,768\n          Conv2d-125          [-1, 256, 20, 30]          32,768\n     BatchNorm2d-126          [-1, 256, 20, 30]             512\n     BatchNorm2d-127          [-1, 256, 20, 30]             512\n            ReLU-128          [-1, 256, 20, 30]               0\n            ReLU-129          [-1, 256, 20, 30]               0\n        ResBlock-130          [-1, 256, 20, 30]               0\n        ResBlock-131          [-1, 256, 20, 30]               0\n          Conv2d-132          [-1, 256, 20, 30]         589,824\n          Conv2d-133          [-1, 256, 20, 30]         589,824\n     BatchNorm2d-134          [-1, 256, 20, 30]             512\n     BatchNorm2d-135          [-1, 256, 20, 30]             512\n            ReLU-136          [-1, 256, 20, 30]               0\n            ReLU-137          [-1, 256, 20, 30]               0\n          Conv2d-138          [-1, 256, 20, 30]         589,824\n          Conv2d-139          [-1, 256, 20, 30]         589,824\n     BatchNorm2d-140          [-1, 256, 20, 30]             512\n     BatchNorm2d-141          [-1, 256, 20, 30]             512\n            ReLU-142          [-1, 256, 20, 30]               0\n            ReLU-143          [-1, 256, 20, 30]               0\n        ResBlock-144          [-1, 256, 20, 30]               0\n        ResBlock-145          [-1, 256, 20, 30]               0\n          Conv2d-146          [-1, 256, 20, 30]         589,824\n          Conv2d-147          [-1, 256, 20, 30]         589,824\n     BatchNorm2d-148          [-1, 256, 20, 30]             512\n     BatchNorm2d-149          [-1, 256, 20, 30]             512\n            ReLU-150          [-1, 256, 20, 30]               0\n            ReLU-151          [-1, 256, 20, 30]               0\n          Conv2d-152          [-1, 256, 20, 30]         589,824\n          Conv2d-153          [-1, 256, 20, 30]         589,824\n     BatchNorm2d-154          [-1, 256, 20, 30]             512\n     BatchNorm2d-155          [-1, 256, 20, 30]             512\n            ReLU-156          [-1, 256, 20, 30]               0\n            ReLU-157          [-1, 256, 20, 30]               0\n        ResBlock-158          [-1, 256, 20, 30]               0\n        ResBlock-159          [-1, 256, 20, 30]               0\n          Conv2d-160          [-1, 256, 20, 30]         589,824\n          Conv2d-161          [-1, 256, 20, 30]         589,824\n     BatchNorm2d-162          [-1, 256, 20, 30]             512\n     BatchNorm2d-163          [-1, 256, 20, 30]             512\n            ReLU-164          [-1, 256, 20, 30]               0\n            ReLU-165          [-1, 256, 20, 30]               0\n          Conv2d-166          [-1, 256, 20, 30]         589,824\n          Conv2d-167          [-1, 256, 20, 30]         589,824\n     BatchNorm2d-168          [-1, 256, 20, 30]             512\n     BatchNorm2d-169          [-1, 256, 20, 30]             512\n            ReLU-170          [-1, 256, 20, 30]               0\n            ReLU-171          [-1, 256, 20, 30]               0\n        ResBlock-172          [-1, 256, 20, 30]               0\n        ResBlock-173          [-1, 256, 20, 30]               0\n          Conv2d-174          [-1, 256, 20, 30]         589,824\n          Conv2d-175          [-1, 256, 20, 30]         589,824\n     BatchNorm2d-176          [-1, 256, 20, 30]             512\n     BatchNorm2d-177          [-1, 256, 20, 30]             512\n            ReLU-178          [-1, 256, 20, 30]               0\n            ReLU-179          [-1, 256, 20, 30]               0\n          Conv2d-180          [-1, 256, 20, 30]         589,824\n          Conv2d-181          [-1, 256, 20, 30]         589,824\n     BatchNorm2d-182          [-1, 256, 20, 30]             512\n     BatchNorm2d-183          [-1, 256, 20, 30]             512\n            ReLU-184          [-1, 256, 20, 30]               0\n            ReLU-185          [-1, 256, 20, 30]               0\n        ResBlock-186          [-1, 256, 20, 30]               0\n        ResBlock-187          [-1, 256, 20, 30]               0\n          Conv2d-188          [-1, 256, 20, 30]         589,824\n          Conv2d-189          [-1, 256, 20, 30]         589,824\n     BatchNorm2d-190          [-1, 256, 20, 30]             512\n     BatchNorm2d-191          [-1, 256, 20, 30]             512\n            ReLU-192          [-1, 256, 20, 30]               0\n            ReLU-193          [-1, 256, 20, 30]               0\n          Conv2d-194          [-1, 256, 20, 30]         589,824\n          Conv2d-195          [-1, 256, 20, 30]         589,824\n     BatchNorm2d-196          [-1, 256, 20, 30]             512\n     BatchNorm2d-197          [-1, 256, 20, 30]             512\n            ReLU-198          [-1, 256, 20, 30]               0\n            ReLU-199          [-1, 256, 20, 30]               0\n        ResBlock-200          [-1, 256, 20, 30]               0\n        ResBlock-201          [-1, 256, 20, 30]               0\n          Conv2d-202          [-1, 128, 20, 30]          32,896\n          Conv2d-203          [-1, 512, 10, 15]       1,179,648\n          Conv2d-204          [-1, 512, 10, 15]       1,179,648\n     BatchNorm2d-205          [-1, 512, 10, 15]           1,024\n     BatchNorm2d-206          [-1, 512, 10, 15]           1,024\n            ReLU-207          [-1, 512, 10, 15]               0\n            ReLU-208          [-1, 512, 10, 15]               0\n          Conv2d-209          [-1, 512, 10, 15]       2,359,296\n          Conv2d-210          [-1, 512, 10, 15]       2,359,296\n     BatchNorm2d-211          [-1, 512, 10, 15]           1,024\n     BatchNorm2d-212          [-1, 512, 10, 15]           1,024\n          Conv2d-213          [-1, 512, 10, 15]         131,072\n          Conv2d-214          [-1, 512, 10, 15]         131,072\n     BatchNorm2d-215          [-1, 512, 10, 15]           1,024\n     BatchNorm2d-216          [-1, 512, 10, 15]           1,024\n            ReLU-217          [-1, 512, 10, 15]               0\n            ReLU-218          [-1, 512, 10, 15]               0\n        ResBlock-219          [-1, 512, 10, 15]               0\n        ResBlock-220          [-1, 512, 10, 15]               0\n          Conv2d-221          [-1, 512, 10, 15]       2,359,296\n          Conv2d-222          [-1, 512, 10, 15]       2,359,296\n     BatchNorm2d-223          [-1, 512, 10, 15]           1,024\n     BatchNorm2d-224          [-1, 512, 10, 15]           1,024\n            ReLU-225          [-1, 512, 10, 15]               0\n            ReLU-226          [-1, 512, 10, 15]               0\n          Conv2d-227          [-1, 512, 10, 15]       2,359,296\n          Conv2d-228          [-1, 512, 10, 15]       2,359,296\n     BatchNorm2d-229          [-1, 512, 10, 15]           1,024\n     BatchNorm2d-230          [-1, 512, 10, 15]           1,024\n            ReLU-231          [-1, 512, 10, 15]               0\n            ReLU-232          [-1, 512, 10, 15]               0\n        ResBlock-233          [-1, 512, 10, 15]               0\n        ResBlock-234          [-1, 512, 10, 15]               0\n          Conv2d-235          [-1, 512, 10, 15]       2,359,296\n          Conv2d-236          [-1, 512, 10, 15]       2,359,296\n     BatchNorm2d-237          [-1, 512, 10, 15]           1,024\n     BatchNorm2d-238          [-1, 512, 10, 15]           1,024\n            ReLU-239          [-1, 512, 10, 15]               0\n            ReLU-240          [-1, 512, 10, 15]               0\n          Conv2d-241          [-1, 512, 10, 15]       2,359,296\n          Conv2d-242          [-1, 512, 10, 15]       2,359,296\n     BatchNorm2d-243          [-1, 512, 10, 15]           1,024\n     BatchNorm2d-244          [-1, 512, 10, 15]           1,024\n            ReLU-245          [-1, 512, 10, 15]               0\n            ReLU-246          [-1, 512, 10, 15]               0\n        ResBlock-247          [-1, 512, 10, 15]               0\n        ResBlock-248          [-1, 512, 10, 15]               0\n          Conv2d-249          [-1, 512, 10, 15]         262,656\n ConvTranspose2d-250          [-1, 128, 20, 30]         262,272\n            ReLU-251          [-1, 256, 20, 30]               0\n     BatchNorm2d-252          [-1, 256, 20, 30]             512\nAdaptiveAvgPool2d-253            [-1, 256, 1, 1]               0\n          Linear-254                  [-1, 128]          32,896\n            ReLU-255                  [-1, 128]               0\n          Linear-256                  [-1, 256]          33,024\n         Sigmoid-257                  [-1, 256]               0\n        CSEBlock-258          [-1, 256, 20, 30]               0\n          Conv2d-259            [-1, 1, 20, 30]             257\n         Sigmoid-260            [-1, 1, 20, 30]               0\n        SSEBlock-261          [-1, 256, 20, 30]               0\n       SCSEBlock-262          [-1, 256, 20, 30]               0\n     UpsampBlock-263          [-1, 256, 20, 30]               0\n ConvTranspose2d-264          [-1, 128, 40, 60]         131,200\n            ReLU-265          [-1, 256, 40, 60]               0\n     BatchNorm2d-266          [-1, 256, 40, 60]             512\nAdaptiveAvgPool2d-267            [-1, 256, 1, 1]               0\n          Linear-268                  [-1, 128]          32,896\n            ReLU-269                  [-1, 128]               0\n          Linear-270                  [-1, 256]          33,024\n         Sigmoid-271                  [-1, 256]               0\n        CSEBlock-272          [-1, 256, 40, 60]               0\n          Conv2d-273            [-1, 1, 40, 60]             257\n         Sigmoid-274            [-1, 1, 40, 60]               0\n        SSEBlock-275          [-1, 256, 40, 60]               0\n       SCSEBlock-276          [-1, 256, 40, 60]               0\n     UpsampBlock-277          [-1, 256, 40, 60]               0\n ConvTranspose2d-278         [-1, 128, 80, 120]         131,200\n            ReLU-279         [-1, 256, 80, 120]               0\n     BatchNorm2d-280         [-1, 256, 80, 120]             512\nAdaptiveAvgPool2d-281            [-1, 256, 1, 1]               0\n          Linear-282                  [-1, 128]          32,896\n            ReLU-283                  [-1, 128]               0\n          Linear-284                  [-1, 256]          33,024\n         Sigmoid-285                  [-1, 256]               0\n        CSEBlock-286         [-1, 256, 80, 120]               0\n          Conv2d-287           [-1, 1, 80, 120]             257\n         Sigmoid-288           [-1, 1, 80, 120]               0\n        SSEBlock-289         [-1, 256, 80, 120]               0\n       SCSEBlock-290         [-1, 256, 80, 120]               0\n     UpsampBlock-291         [-1, 256, 80, 120]               0\n ConvTranspose2d-292        [-1, 128, 160, 240]         131,200\n            ReLU-293        [-1, 256, 160, 240]               0\n     BatchNorm2d-294        [-1, 256, 160, 240]             512\nAdaptiveAvgPool2d-295            [-1, 256, 1, 1]               0\n          Linear-296                  [-1, 128]          32,896\n            ReLU-297                  [-1, 128]               0\n          Linear-298                  [-1, 256]          33,024\n         Sigmoid-299                  [-1, 256]               0\n        CSEBlock-300        [-1, 256, 160, 240]               0\n          Conv2d-301          [-1, 1, 160, 240]             257\n         Sigmoid-302          [-1, 1, 160, 240]               0\n        SSEBlock-303        [-1, 256, 160, 240]               0\n       SCSEBlock-304        [-1, 256, 160, 240]               0\n     UpsampBlock-305        [-1, 256, 160, 240]               0\n ConvTranspose2d-306          [-1, 1, 320, 480]           1,025\n================================================================\nTotal params: 43,821,701\nTrainable params: 43,821,701\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 1.76\nForward/backward pass size (MB): 1289.29\nParams size (MB): 167.17\nEstimated Total Size (MB): 1458.21\n----------------------------------------------------------------\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00002-be99499f-61a3-432a-8221-af177c0977ff",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "13f08aca",
    "execution_millis": 694,
    "execution_start": 1616684408321,
    "deepnote_cell_type": "code"
   },
   "source": "# Sjoerd\nimport os, sys\nsys.path.append(os.path.join(os.path.dirname(os.path.abspath(\"\")), '..'))\n\n\nfrom work.CFD.data import CFD\nfrom torch.utils.data import random_split\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\nimport torch\n\n\ntotensor = transforms.ToTensor()\ndataset = CFD(\"../CFD/cfd_image\", totensor, \"../CFD/seg_gt\", totensor)\ngen = torch.Generator().manual_seed(42)\ntrain_data, test_data = random_split(dataset, [71, 47], gen)\n\ntrain_loader = DataLoader(train_data, batch_size=10)\ntest_loader = DataLoader(test_data, batch_size=47)\n\n\n# fig, axs = plt.subplots(5, 5, figsize=(5, 5))\n# for i in range(25):\n#     _, gt = test_data[i]\n#     ax = axs[i // 5][i % 5]\n#     ax.imshow(gt.view(320, 480), cmap=\"gray\")\n#     ax.axis(\"off\")\n# plt.tight_layout()\n# plt.show()\n\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00004-7428292d-49f2-411d-8364-8347593a3c9e",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d3235d1a",
    "execution_millis": 68,
    "execution_start": 1616684409029,
    "deepnote_cell_type": "code"
   },
   "source": "# Some functions used during training\n\ndef try_gpu():\n    \"\"\"\n    If GPU is available, return torch.device as cuda:0; else return torch.device\n    as cpu.\n    \"\"\"\n    if torch.cuda.is_available():\n        device = torch.device('cuda:0')\n    else:\n        device = torch.device('cpu')\n    return device\n\n\ndef evaluate_accuracy(data_loader, network, device=torch.device('cpu')):\n    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n    network.eval()  #make sure network is in evaluation mode\n\n    #init\n    acc_sum = torch.tensor([0], dtype=torch.float32, device=device)\n    n = 0\n\n    for X, y in data_loader:\n        # Copy the data to device.\n        X, y = X.to(device), y.to(device)\n        with torch.no_grad():\n            y = y.long()\n            acc_sum += torch.sum((torch.argmax(network(X), dim=1) == y))\n            n += y.shape[0] #increases with the number of samples in the batch\n    return acc_sum.item()/n\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00004-a65cc30d-dddc-41df-9d94-28845042d191",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "496a89e2",
    "execution_millis": 45,
    "execution_start": 1616684471202,
    "deepnote_cell_type": "code"
   },
   "source": "from loss import dice_loss\n\n# training parameters\nlr = 1e-3\nepochs = 1\n\n#Initialize network\nnetwork = main.Net()\noptimizer = torch.optim.AdamW(network.parameters(), lr=lr, betas=(0.9, 0.999))\ncriterion = dice_loss.batch_dice_loss\n\n# Define list to store losses and performances of each interation\ntrain_losses = []\ntrain_accs = []\ntest_accs = []\n\n# Try using gpu instead of cpu\ndevice = try_gpu()\n\nfor epoch in range(epochs):\n\n    # Network in training mode and to device\n    network.train()\n    network.to(device)\n\n    # Training loop\n    for i, (x_batch, y_batch) in enumerate(train_loader):\n\n         # Set to same device\n         x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n\n         # Set the gradients to zero\n         optimizer.zero_grad()\n\n         # Perform forward pass\n         y_pred = network(x_batch)\n\n         # Compute the loss\n         loss = criterion(y_pred, y_batch)\n         train_losses.append(loss)\n\n         # Backward computation and update\n         loss.backward()\n         optimizer.step()\n    \n    # Compute train and test error\n    train_acc = 100*evaluate_accuracy(train_loader, network.to('cpu'))\n    test_acc = 100*evaluate_accuracy(test_loader, network.to('cpu'))\n    \n    # Development of performance\n    train_accs.append(train_acc)\n    test_accs.append(test_acc)\n\n    # Print performance\n    print('Epoch: {:.0f}'.format(epoch+1))\n    print('Accuracy of train set: {:.00f}%'.format(train_acc))\n    print('Accuracy of test set: {:.00f}%'.format(test_acc))\n    print('')\n",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'NetBlock' is not defined",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-8-1e9003e09ce5>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;31m#Initialize network\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m \u001B[0mnetwork\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mNetBlock\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m \u001B[0moptimizer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptim\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mAdamW\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnetwork\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlr\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbetas\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0.9\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0.999\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0mcriterion\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbatch_dice_loss\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'NetBlock' is not defined"
     ]
    },
    {
     "output_type": "error",
     "ename": "KernelInterrupted",
     "evalue": "Execution interrupted by the Jupyter kernel.",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKernelInterrupted\u001B[0m: Execution interrupted by the Jupyter kernel."
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00002-ee16a739-e3a0-4689-a9ed-33c171733c59",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "7be1a9b6",
    "execution_millis": 1981,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "# from torchviz import make_dot\n\n# x = torch.randn(1,3, 320, 480)\n# y = net(x) \n\n# make_dot(y).view()",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'xdg-open'",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-3-e75b9e2e7fd1>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnet\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m \u001B[0mmake_dot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mview\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/venv/lib/python3.8/site-packages/graphviz/files.py\u001B[0m in \u001B[0;36mview\u001B[0;34m(self, filename, directory, cleanup, quiet, quiet_view)\u001B[0m\n\u001B[1;32m    280\u001B[0m             \u001B[0mto\u001B[0m \u001B[0mretrieve\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mapplication\u001B[0m\u001B[0;31m'\u001B[0m\u001B[0ms\u001B[0m \u001B[0mexit\u001B[0m \u001B[0mstatus\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    281\u001B[0m         \"\"\"\n\u001B[0;32m--> 282\u001B[0;31m         return self.render(filename=filename, directory=directory,\n\u001B[0m\u001B[1;32m    283\u001B[0m                            \u001B[0mview\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcleanup\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcleanup\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    284\u001B[0m                            quiet=quiet, quiet_view=quiet_view)\n",
      "\u001B[0;32m~/venv/lib/python3.8/site-packages/graphviz/files.py\u001B[0m in \u001B[0;36mrender\u001B[0;34m(self, filename, directory, view, cleanup, format, renderer, formatter, quiet, quiet_view)\u001B[0m\n\u001B[1;32m    250\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    251\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mquiet_view\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mview\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 252\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_view\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrendered\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_format\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mquiet_view\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    253\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    254\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mrendered\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/venv/lib/python3.8/site-packages/graphviz/files.py\u001B[0m in \u001B[0;36m_view\u001B[0;34m(self, filepath, format, quiet)\u001B[0m\n\u001B[1;32m    298\u001B[0m                                ' on %r platform' % (self.__class__, format,\n\u001B[1;32m    299\u001B[0m                                                     backend.PLATFORM))\n\u001B[0;32m--> 300\u001B[0;31m         \u001B[0mview_method\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilepath\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mquiet\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    301\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    302\u001B[0m     \u001B[0m_view_darwin\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mstaticmethod\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbackend\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mview\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdarwin\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/venv/lib/python3.8/site-packages/graphviz/backend.py\u001B[0m in \u001B[0;36mview_unixoid\u001B[0;34m(filepath, quiet)\u001B[0m\n\u001B[1;32m    365\u001B[0m     \u001B[0mlog\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdebug\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'view: %r'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcmd\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    366\u001B[0m     \u001B[0mpopen_func\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_compat\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mPopen_stderr_devnull\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mquiet\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0msubprocess\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mPopen\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 367\u001B[0;31m     \u001B[0mpopen_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcmd\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    368\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    369\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/subprocess.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001B[0m\n\u001B[1;32m    856\u001B[0m                             encoding=encoding, errors=errors)\n\u001B[1;32m    857\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 858\u001B[0;31m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001B[0m\u001B[1;32m    859\u001B[0m                                 \u001B[0mpass_fds\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcwd\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0menv\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    860\u001B[0m                                 \u001B[0mstartupinfo\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreationflags\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshell\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/subprocess.py\u001B[0m in \u001B[0;36m_execute_child\u001B[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001B[0m\n\u001B[1;32m   1704\u001B[0m                     \u001B[0;32mif\u001B[0m \u001B[0merrno_num\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1705\u001B[0m                         \u001B[0merr_msg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstrerror\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0merrno_num\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1706\u001B[0;31m                     \u001B[0;32mraise\u001B[0m \u001B[0mchild_exception_type\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0merrno_num\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merr_msg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merr_filename\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1707\u001B[0m                 \u001B[0;32mraise\u001B[0m \u001B[0mchild_exception_type\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0merr_msg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1708\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'xdg-open'"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=411d58e9-cb4b-4924-bef0-2f383eff0187' target=\"_blank\">\n<img style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz4KPHN2ZyB3aWR0aD0iODBweCIgaGVpZ2h0PSI4MHB4IiB2aWV3Qm94PSIwIDAgODAgODAiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayI+CiAgICA8IS0tIEdlbmVyYXRvcjogU2tldGNoIDU0LjEgKDc2NDkwKSAtIGh0dHBzOi8vc2tldGNoYXBwLmNvbSAtLT4KICAgIDx0aXRsZT5Hcm91cCAzPC90aXRsZT4KICAgIDxkZXNjPkNyZWF0ZWQgd2l0aCBTa2V0Y2guPC9kZXNjPgogICAgPGcgaWQ9IkxhbmRpbmciIHN0cm9rZT0ibm9uZSIgc3Ryb2tlLXdpZHRoPSIxIiBmaWxsPSJub25lIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiPgogICAgICAgIDxnIGlkPSJBcnRib2FyZCIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoLTEyMzUuMDAwMDAwLCAtNzkuMDAwMDAwKSI+CiAgICAgICAgICAgIDxnIGlkPSJHcm91cC0zIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSgxMjM1LjAwMDAwMCwgNzkuMDAwMDAwKSI+CiAgICAgICAgICAgICAgICA8cG9seWdvbiBpZD0iUGF0aC0yMCIgZmlsbD0iIzAyNjVCNCIgcG9pbnRzPSIyLjM3NjIzNzYyIDgwIDM4LjA0NzY2NjcgODAgNTcuODIxNzgyMiA3My44MDU3NTkyIDU3LjgyMTc4MjIgMzIuNzU5MjczOSAzOS4xNDAyMjc4IDMxLjY4MzE2ODMiPjwvcG9seWdvbj4KICAgICAgICAgICAgICAgIDxwYXRoIGQ9Ik0zNS4wMDc3MTgsODAgQzQyLjkwNjIwMDcsNzYuNDU0OTM1OCA0Ny41NjQ5MTY3LDcxLjU0MjI2NzEgNDguOTgzODY2LDY1LjI2MTk5MzkgQzUxLjExMjI4OTksNTUuODQxNTg0MiA0MS42NzcxNzk1LDQ5LjIxMjIyODQgMjUuNjIzOTg0Niw0OS4yMTIyMjg0IEMyNS40ODQ5Mjg5LDQ5LjEyNjg0NDggMjkuODI2MTI5Niw0My4yODM4MjQ4IDM4LjY0NzU4NjksMzEuNjgzMTY4MyBMNzIuODcxMjg3MSwzMi41NTQ0MjUgTDY1LjI4MDk3Myw2Ny42NzYzNDIxIEw1MS4xMTIyODk5LDc3LjM3NjE0NCBMMzUuMDA3NzE4LDgwIFoiIGlkPSJQYXRoLTIyIiBmaWxsPSIjMDAyODY4Ij48L3BhdGg+CiAgICAgICAgICAgICAgICA8cGF0aCBkPSJNMCwzNy43MzA0NDA1IEwyNy4xMTQ1MzcsMC4yNTcxMTE0MzYgQzYyLjM3MTUxMjMsLTEuOTkwNzE3MDEgODAsMTAuNTAwMzkyNyA4MCwzNy43MzA0NDA1IEM4MCw2NC45NjA0ODgyIDY0Ljc3NjUwMzgsNzkuMDUwMzQxNCAzNC4zMjk1MTEzLDgwIEM0Ny4wNTUzNDg5LDc3LjU2NzA4MDggNTMuNDE4MjY3Nyw3MC4zMTM2MTAzIDUzLjQxODI2NzcsNTguMjM5NTg4NSBDNTMuNDE4MjY3Nyw0MC4xMjg1NTU3IDM2LjMwMzk1NDQsMzcuNzMwNDQwNSAyNS4yMjc0MTcsMzcuNzMwNDQwNSBDMTcuODQzMDU4NiwzNy43MzA0NDA1IDkuNDMzOTE5NjYsMzcuNzMwNDQwNSAwLDM3LjczMDQ0MDUgWiIgaWQ9IlBhdGgtMTkiIGZpbGw9IiMzNzkzRUYiPjwvcGF0aD4KICAgICAgICAgICAgPC9nPgogICAgICAgIDwvZz4KICAgIDwvZz4KPC9zdmc+' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote_notebook_id": "96775278-d606-4bc7-a96c-64fcdaf37c69",
  "deepnote": {},
  "deepnote_execution_queue": []
 }
}