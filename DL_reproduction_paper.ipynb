{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Setup Colab\n",
    "### load files quickly"
   ],
   "metadata": {
    "tags": [],
    "cell_id": "00000-aa1ebb43-bd43-4a30-89eb-9a2fbe273df7",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00001-661d49a9-fbb7-418a-93da-aecefc4bf03e",
    "deepnote_cell_type": "code"
   },
   "source": [
    "!git clone -b new_version https://github.com/ReinierKoops/DL_crack_segmentation.git"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00002-f5b082d2-1122-48fd-a78a-3c186e4c5159",
    "deepnote_cell_type": "code"
   },
   "source": [
    "# Select the appropriate folder\n",
    "Project_folder = 'DL_crack_segmentation'\n",
    "\n",
    "# Allow importing of Python & dataset files\n",
    "import sys\n",
    "sys.path.append(Project_folder)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00001-3f234d6f-7dc7-46fb-beeb-177ee70228b4",
    "deepnote_cell_type": "code"
   },
   "source": [
    "# Install packages on Colab\n",
    "!pip install torchinfo gdown\n",
    "# Download datasets quickly from Google Drive into fast memory\n",
    "!gdown --id 1uLCnPgFH_UP2JNsFUPyiaUkSLWDuNkCd"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00002-7d80559c-acec-42c0-af24-d2f0918d7ef3",
    "deepnote_cell_type": "code"
   },
   "source": [
    "# Unzip the datasets\n",
    "!unzip datasets.zip"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Reproduce DL\n",
    "## Automated Pavement Crack Segmentation\n",
    "\n",
    "We start by setting up the actual Architecture. This means making sure all weights are properly initialized and all layers are connected. \n",
    "\n",
    "We make use of PyTorch for the implementation.\n",
    "\n",
    "Multiple parts come together (A U-based ResNet);\n",
    "- We recreate ResNet34 and remove the last two layers\n",
    "- We made sure that a ResNet-block is either 4 or 6 layers depending on if stride is not 1 (which in our case always happens when the in_channels are not equal to out_channels)\n",
    "- We use transfer learning such that the ResNet34 parameters are initialized as if trained on ImageNet\n",
    "- We create Squeeze and Excitation blocks that are applied per Channel (cSE) and per Spatial (sSE) (image)\n",
    "- These two blocks are combined (scSE) and then the maximum of this is taken\n",
    "- Each convolutional layer its parameters are initialized via \"He Kaiming\" method."
   ],
   "metadata": {
    "cell_id": "00000-82d331e0-79e4-40f0-ba43-0ad2ccc7fea5",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00001-7e91ba22-24c3-47de-a4fc-1812208e0fff",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "e71acbdd",
    "execution_millis": 87,
    "output_cleared": false,
    "execution_start": 1618401308314,
    "deepnote_cell_type": "code"
   },
   "source": [
    "# Do all the imports\n",
    "## Packages\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "from torchinfo import summary\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "## Project\n",
    "from architecture import main\n",
    "from loss.loss import batch_dice_loss\n",
    "from utils.parameters import layer_split\n",
    "from utils.device import try_gpu\n",
    "from utils.dataset import get_data_loaders\n",
    "from evaluation.binary_classification import get_prec_recall, get_f1\n",
    "\n",
    "# Define dataset \"CFD\" or \"CRACK500\"\n",
    "datasetname = \"CFD\"\n",
    "# Try using GPU, otherwise CPU\n",
    "device = try_gpu()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00004-a65cc30d-dddc-41df-9d94-28845042d191",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1958,
    "output_cleared": true,
    "source_hash": null,
    "tags": [],
    "execution_start": 1617360992742,
    "is_code_hidden": false,
    "deepnote_cell_type": "code"
   },
   "source": [
    "# Always needs to be a factor of 3\n",
    "# Phase 1 = 1/3 time, Phase 2 = 2/3 time\n",
    "EPOCHS = 45\n",
    "epochs_1 = ( EPOCHS // 3 )\n",
    "epochs_2 = ( EPOCHS // 3 ) * 2\n",
    "\n",
    "# Define list to store losses and performances of each interation\n",
    "metrics = []\n",
    "#Initialize network\n",
    "network = main.Net()\n",
    "#Initiliaze loss function\n",
    "criterion = batch_dice_loss\n",
    "\n",
    "# Split layers into three, for seperate optimization\n",
    "layer_1, layer_2, layer_3 = layer_split(network)\n",
    "\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {'params': layer_1, 'name': 'layer_1'},\n",
    "    {'params': layer_2, 'name': 'layer_2'},\n",
    "    {'params': layer_3, 'name': 'layer_3'}], betas=(0.9, 0.999), weight_decay = 0.01)\n",
    "\n",
    "## batch sizes (dependend on hardware)\n",
    "# Train: should be neither too small nor too large (CFD: 5, C5D: 30) - Colab Pro\n",
    "bs_train = 5\n",
    "# Test: should be as high as possible (CFD: 48, C5D: 150) - Colab Pro\n",
    "bs_test = 48\n",
    "\n",
    "# Image factor explanation:\n",
    "# 1 = 320, 0.8 = 256, 0.4 = 128\n",
    "# Get dataloaders (128x128)\n",
    "dataset, train_loader, test_loader = get_data_loaders(\n",
    "    bs_train, \n",
    "    bs_test, \n",
    "    0.4, \n",
    "    datasetname\n",
    "    )\n",
    "\n",
    "# Look at this more carefully\n",
    "# it should do this:\n",
    "# - max lr is 0.005\n",
    "# - start at 5% (0.05) of max_lr \n",
    "# - linearly build up\n",
    "# - max_lr at (total_epoch * 0.4)\n",
    "# - linearly break down\n",
    "# - end at 0.00005 lr at last epoch\n",
    "# Three phase: \n",
    "# - Up from initial to max,\n",
    "# - Down from max to initial,\n",
    "# - Down from initial to minimum\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=0.005,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    anneal_strategy='linear',\n",
    "    pct_start=0.4, \n",
    "    div_factor=20,\n",
    "    final_div_factor=20000,\n",
    "    three_phase=True\n",
    "    )\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    # Network in training mode and to device\n",
    "    network.train()\n",
    "    network.to(device)\n",
    "    \n",
    "    optimizer.param_groups[0][\"lr\"] = 0 if epoch < epochs_1 else optimizer.param_groups[2][\"lr\"] / 9\n",
    "    optimizer.param_groups[1][\"lr\"] = optimizer.param_groups[2][\"lr\"] / 3\n",
    "    \n",
    "    if (epoch == epochs_1):\n",
    "        # Get dataloaders (256x256)\n",
    "        dataset, train_loader, test_loader = get_data_loaders(\n",
    "            bs_train, \n",
    "            bs_test, \n",
    "            0.8, \n",
    "            datasetname\n",
    "            )\n",
    "\n",
    "    if (epoch == epochs_2):\n",
    "        # Get dataloaders (320x320)\n",
    "        dataset, train_loader, test_loader = get_data_loaders(\n",
    "            bs_train, \n",
    "            bs_test, \n",
    "            1, \n",
    "            datasetname\n",
    "            )\n",
    "\n",
    "    # Training loop\n",
    "    for i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "\n",
    "        # Set to same device\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        # Set the gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform forward pass\n",
    "        y_pred = network(x_batch)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "\n",
    "        # Backward computation and update\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "    # Compute precision, recall, and f1 for train and test data\n",
    "    train_prec, train_recall = get_prec_recall(train_loader, network.to(device), device)\n",
    "    train_f1 = get_f1(train_prec, train_recall)\n",
    "    test_prec, test_recall = get_prec_recall(test_loader, network.to(device), device)\n",
    "    test_f1 = get_f1(test_prec, test_recall)\n",
    "    metrics.append([(epoch+1), train_prec, train_recall, train_f1, test_prec, test_recall, test_f1, loss.tolist()])\n",
    "\n",
    "    # Print out stats three times\n",
    "    if (epoch+1) % (EPOCHS // 3) == 0:\n",
    "        # Print performance\n",
    "        print('Epoch: {:.0f}'.format(epoch+1))\n",
    "        print(f'Precision, Recall, and F1 of test set: {test_prec}, {test_recall}, {test_f1}')\n",
    "        print('')\n",
    "\n",
    "\n",
    "# Save model\n",
    "model_state = network.state_dict()\n",
    "torch.save(model_state, \"model_parameters.pt\")\n",
    "\n",
    "# Write metrics to disk\n",
    "df = pd.DataFrame(metrics, columns=[\n",
    "    \"epoch\", \"train_prec\", \"train_recall\", \"train_f1\", \"test_prec\", \"test_recall\", \"test_f1\", \"loss\"])\n",
    "df.to_csv(\"metrics.csv\", index=False)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00008-55ee9151-d60f-4808-b4e0-9f491fe83c6a",
    "deepnote_cell_type": "code"
   },
   "source": [
    "def epoch_to_PIL(data_loader, network, device) -> dict:\n",
    "    converted = {\"xs\": [], \"ys\": [], \"preds\": []}\n",
    "    count = 0\n",
    "    for x_batch, y_batch in data_loader:\n",
    "      if (count > 10):\n",
    "        break\n",
    "      preds = network(x_batch)\n",
    "      converted[\"xs\"].extend(batch_to_PIL(x_batch))\n",
    "      converted[\"ys\"].extend(batch_to_PIL(y_batch))\n",
    "      converted[\"preds\"].extend(batch_to_PIL(preds))\n",
    "      count = count + 1\n",
    "    return converted\n",
    "\n",
    "\n",
    "def batch_to_PIL(tensor_batch) -> list:\n",
    "    converted = []\n",
    "    for t in tensor_batch:\n",
    "        img = transforms.ToPILImage()(t)\n",
    "        converted.append(img)\n",
    "    return converted\n",
    "\n",
    "\n",
    "# Params\n",
    "bs_train = 5 # batch size train\n",
    "bs_test = 20 # batch size test\n",
    "dataset, train_loader, test_loader = get_data_loaders(\n",
    "            bs_train, \n",
    "            bs_test, \n",
    "            1, \n",
    "            datasetname\n",
    "            )\n",
    "network = main.Net()\n",
    "network.load_state_dict(torch.load(\"model_parameters.pt\"))\n",
    "network.eval()\n",
    "pics = epoch_to_PIL(test_loader, network, device)\n",
    "n_examples = 10\n",
    "f, axarr = plt.subplots(n_examples, 3, figsize=(15, n_examples*4)) \n",
    "\n",
    "for i in range(n_examples):\n",
    "    axarr[i][0].imshow(pics[\"xs\"][i])\n",
    "    axarr[i][1].imshow(pics[\"ys\"][i])\n",
    "    axarr[i][2].imshow(pics[\"preds\"][i])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00009-33ee83a7-ab83-4eb4-811f-2dc28934f96d",
    "deepnote_to_be_reexecuted": false,
    "source_hash": null,
    "execution_millis": 2073,
    "execution_start": 1618401416362,
    "output_cleared": true,
    "deepnote_cell_type": "code",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Summarize the Architecture as output\n",
    "network = main.Net()\n",
    "model = network.to(device)\n",
    "\n",
    "# print(network)\n",
    "model_ouput = summary(\n",
    "    model, \n",
    "    (1, 3, 320, 480),\n",
    "    verbose=2,\n",
    "    col_width=16,\n",
    "    col_names=[\"kernel_size\", \"input_size\", \"output_size\", \"num_params\"])"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 4,
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "96775278-d606-4bc7-a96c-64fcdaf37c69",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 }
}